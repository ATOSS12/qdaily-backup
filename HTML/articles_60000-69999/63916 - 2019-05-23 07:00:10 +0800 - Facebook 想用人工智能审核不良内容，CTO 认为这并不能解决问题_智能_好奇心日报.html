<h1>Facebook 想用人工智能审核不良内容，CTO 认为这并不能解决问题_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20190521105805UyadP6cCk3tjXVnG.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://m.qdaily.com/images/missing_face.png"/> </a>  <span class="name">Cade Metz and Mike Isaac</span><span class="date smart-date" data-origindate="2019-05-23 07:00:10 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2019-05-23 07:00:10</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="63916" data-title="《Facebook 想用人工智能审核不良内容，CTO 认为这并不能解决问题》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20190521105805UyadP6cCk3tjXVnG.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/63916.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="57"/></a>  </div></div> </div>  <p class="excerpt">一场无休无止的战役。</p>  <div class="detail">  

<p finallycleanhtml="true" nocleanhtml="true"><strong><em>＊<a href="https://www.nytimes.com/2019/05/17/technology/facebook-ai-schroepfer.html" rel="nofollow">本文</a>只能在《好奇心日报》发布，即使我们允许了也不许转载＊</em></strong></p>
<p>加利福尼亚州门洛帕克电（MENLO PARK）— Facebook 首席技术官迈克·施罗普夫（Mike Schroepfer）在接受《纽约时报》采访时数次哽咽，他的眼角常常闪动着泪光。<br/></p>
<p>我与施罗普夫坐在 Facebook 总部的一间会议室里，四周墙面挂满了涂着蓝、红标记的白板。在半个小时的采访中，我们讨论了从 Facebook 页面上屏蔽不良信息的技术难点，并提到了一件足以证明信息过滤系统识别能力极限的事实：影响恶劣的新西兰克赖斯特彻奇（Christchurch）枪击案直播事件。<br/></p>
<p>今年 3 月，一名枪手<a href="https://www.nytimes.com/2019/03/14/world/asia/christchurch-shooting-new-zealand.html?module=inline" rel="nofollow">在克赖斯特彻奇的两座清真寺里杀害了 51 人</a>，并在 Facebook 上直播了行凶过程。Facebook 花了一个小时才将视频从其网站上移除，不过为时已晚，这段血腥的视频已经在社交媒体上传播开了。<br/></p>
<p>谈到这个问题时施罗普夫沉默了许久，他的眼角开始泛着泪光。<br/></p>
<p><img data-format="jpg" data-ratio="0.390549" class="lazylad lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124606JSpdaCk3eAlgqD5x.jpg-w600"/></p>
<p>“我们正在努力解决这个问题。”他沉默了整整一分钟，努力保持着镇静。“我们不可能在短期内升级信息识别系统，不过再过六个月我们就能修复这个漏洞，甚至可以做得更好。”<br/></p>
<p>问题的关键在于，真的可以完善信息过滤系统，亦或这一切都是 Facebook 在自我安慰。<br/></p>
<p>越来越多的用户在 Facebook 上发布虚假信息、误导消息以及不正当内容，在过去的三年时间里，这家社交媒体公司因为扩散不良信息而屡屡受到政府审查。作为回应，Facebook 首席执行官马克·扎克伯格（Mark Zuckerberg）宣布他们将启用新技术，利用人工智能来删除有问题的帖子。<br/></p>
<p>在去年的国会听证会上，扎克伯格曾<a href="https://www.nytimes.com/2018/04/10/us/politics/mark-zuckerberg-testimony.html?module=inline" rel="nofollow">表示</a> Facebook 正在开发一套机器过滤系统，以“识别特定类别的不良信息”，并宣称“在 5 到 10 年的时间里，我们将拥有能够检测和删除仇恨言论的人工智能工具”。自那以后，他多次在媒体采访、华尔街电话会议以及 Facebook 的内部活动上重复了以上说法。<br/></p>
<p>施罗普夫正是这项任务的负责人，他必须开发出一套自动过滤工具，识别出潜藏在数据海洋中的数百万条不良帖子并将其删除。在最近的三次采访中，他接连表示这是一场无休无止的战役。<br/></p>
<p>这是因为，每当施罗普夫和他的大型专家团队（拥有超过 150 名 AI 开发者）创造出能够标识并删除特定有害信息的过滤系统时，不法分子就会改换发帖方式从而瞒过 AI 系统。而且不同的人对“不良信息”有不同的定义，这使得过滤系统的开发工作难上加难。<br/></p>
<p>一次采访中，施罗普夫在受到刺激后悲观地说道，仅靠人工智能技术无法根除不良信息的扩散问题。他说：“我真的认为我们已经走到了尽头，AI 无法‘解决一切问题’，开发团队应该收拾行李回家。”<br/></p>
<p>抱怨无济于事，问题依然悬而未决。此前一周，由于克赖斯特彻奇直播事件而遭到广泛批评的 Facebook <a href="https://www.nytimes.com/2019/05/14/technology/facebook-live-violent-content.html?module=inline" rel="nofollow">改变了政策</a>，对其流媒体直播服务做出限制。上周三（当地时间 5 月 15 日），在一场由法国总统马克龙（Emmanuel Macron）以及新西兰总理阿德恩（Jacinda Ardern）出席的巴黎峰会上，Facebook <a href="https://www.nytimes.com/2019/05/15/technology/christchurch-call-trump.html?module=inline" rel="nofollow">签署了一项协议</a>，承诺将重新审查其用于识别暴力内容的工具。<br/></p>
<p>现年 44 岁的施罗普夫陷入了一个进退维谷的境地，这从来不是他意想中的局面。多年来，他的工作是帮助 Facebook 建立顶级人工智能实验室，在那里天才程序员可以专注于解决技术难题，比如说使用机器识别照片中的人脸。他和扎克伯格希望<a href="https://www.nytimes.com/2018/02/19/technology/ai-researchers-desks-boss.html?module=inline" rel="nofollow">自家的 AI 技术能够与谷歌一争高下</a>。谷歌被公认为拥有最稳定的 AI 研究团队。施罗普夫为了实现这一目标还从纽约大学、伦敦大学以及巴黎第六大学（Pierre and Marie Curie University）聘请了许多计算机博士。<br/></p>
<p>但在这个过程中，Facebook AI 实验室的研究重点逐渐从技术攻关转变为利用人工智能阻止不良信息传播。目前，团队的大部分时间都花在利用 AI 发现并删除死亡威胁、自杀视频、虚假信息以及各类谣言。<br/></p>
<p>Mozilla 前首席执行官、现为 Greylock Partners 风险投资员的约翰·里利（John Lilly）说：“我们从没有遇到过这类情况，目前并没有关于信息过滤系统的现成方案，这个领域的研究者都是在摸索中前进。”约翰是施罗普夫的校友，他们在 1990 年代中期毕业于斯坦福计算机系。<br/></p>
<p>Facebook 之所以允许施罗普夫接受采访，是因为他们想展示其研究成果，让公众了解 AI 过滤系统如何识别并拦截不良信息，也许他们还想借此机会展现公司的人性化一面。据许多认识施罗普夫的人说，他经常公开表露自己的感受。<br/></p>
<p>Zetta Venture Partners 风险投资家乔斯林·戈德费恩（Jocelyn Goldfein）曾在 Facebook 与施罗普夫共事过一段时间，他说：“我并不是在搬弄是非，施罗普夫真的会在工作中哭泣。”<br/></p>
<p>但没有人能够预料到施罗普夫会对我们提出的问题做出怎样的反应。在两次采访中，他一开始乐观地表示，AI 可能是问题的解决方案，不过谈话间他开始变得有些情绪化。他还表示上班有时会变成一种折磨。每次谈到 Facebook 面临的重大问题，以及自己所肩负的责任时，他都哽咽失声。<br/></p>
<p>他在谈到问题帖子时说：“永远都有新的不良信息出现。”</p>
<h3>任重而道远</h3>
<p>2013 年 12 月的一个周日，克莱门特·法拉贝（Clément Farabet）走进内华达州塔霍湖（Lake Tahoe）哈拉斯酒店（Harrah’s hotel and casino）的顶层套房。施罗普夫和扎克伯格在里面等待着他的到来。<br/></p>
<p>扎克伯格没有穿鞋。在接下来的 30 分钟里，这位穿着袜子的首席执行官来回踱步，与来自纽约大学的人工智能研究员法拉贝特博士展开对话。扎克伯格称人工智能是“未来的热门领域”，也是“Facebook 的下一步研究计划”。坐在沙发上的施罗普夫偶尔会加入他们的对话，抒发自己的见解。<br/></p>
<p>扎克伯格一行人为了招聘 AI 专家来到了这个风景优美的小镇。那一年，塔霍湖是 NIPS 大会的举办地点，这是一个致力于推进 AI 技术发展的学术会议，世界顶尖的 AI 研究人员都出席了此次大会。Facebook 团队还带来了刚刚入职的纽约大学学者杨立昆（Yann LeCun），他被公认为是现代人工智能运动的<a href="https://www.nytimes.com/2019/03/27/technology/turing-award-ai.html?module=inline" rel="nofollow">创始人</a>，Facebook 聘请杨立昆为他们建造一个人工智能实验室。杨立昆无疑是 Facebook 的金字招牌，包括法贝尔在内的许多研究员都把他当成自己的精神领袖。<br/></p>
<p>“他想把所有到场嘉宾收入囊中。”法拉贝特谈到扎克伯格时说。“他知道所有与会研究员的名字。”<br/></p>
<p>在 Facebook 的人工智能实验室转移研究重心前，那段日子可谓风光无限。<br/></p>
<p>虽然近年来从谷歌到 Twitter 等大型科技公司竞相成为人工智能领域的领跑者，但是在此之前，AI 技术一直不被互联网公司看重。不过在大学实验室里，像杨立昆博士这样的科研人员已经悄悄地开发出一种名为“<a href="https://www.nytimes.com/2018/03/06/technology/google-artificial-intelligence.html?module=inline" rel="nofollow">神经网络</a>”的人工智能系统，这是复杂的数学系统，可以通过分析大量数据来找到特定规律。令硅谷的许多企业家感到惊讶的是，这些晦涩难懂又带着几分神秘的智能系统终于有了实际效用。<br/></p>
<p>施罗普夫和扎克伯格希望 Facebook 能够加入到这场竞争中，他们认为迅速发展的 AI 技术可以提高 Facebook 网站的运行效率。施罗普夫表示，人工智能不仅可以让 Facebook 识别出发布在其网站上的照片以及视频中的人脸，还可以帮助网站更好地完成广告宣传活动、组织新闻推送，以及进行<a href="https://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html?module=inline" rel="nofollow">语言翻译</a>。人工智能还可以用于开发“<a href="https://www.nytimes.com/interactive/2018/02/21/technology/conversational-bots.html?module=inline" rel="nofollow">聊天机器人</a>”之类的小型程序，让企业能够高效地与客户完成对话。<br/></p>
<p>施罗普夫说：“我们打算聘请一些世界上最优秀的 AI 人才，并打造一个梦幻般的 AI 实验室。”<br/></p>
<p>从 2013 年开始，施罗普夫开始四处搜罗神经网络专家，当时这个领域的“耀眼明星”通常能在四五年的时间里获得数百万或数千万美元的巨额报酬。不过在塔霍湖的那个周末里，他们没能成功招揽法拉比博士。法拉比后来自立门户，成立了一家人工智能初创企业，并<a href="https://www.wired.com/2014/07/buying-madbits-twitter-wants-image-search-super-powers/" rel="nofollow">被 Twitter 收购</a>。但施罗普夫还是从谷歌、纽约大学以及蒙特利尔大学等地<a href="https://www.nytimes.com/2018/05/04/technology/facebook-artificial-intelligence-researchers.html?module=inline" rel="nofollow">请来了数十名顶尖 AI 科研人员</a>。<br/></p>
<p>施罗普夫还建立了另一支队伍——“机器学习应用团队”（Applied Machine Learning team），他们需要利用 Facebook 人工智能实验室开发出的新技术解决现实生活中的问题，比如说面部识别、语言翻译以及增强现实工具。<br/></p>
<p>发生于 2015 年末的<a href="https://www.nytimes.com/news-event/attacks-in-paris?module=inline" rel="nofollow">巴黎恐怖袭击</a>导致 Facebook 的一些人工智能项目开始改变原本的研究方向。当时，伊斯兰激进分子在巴黎周边发动了一场协同袭击，事件造成 130 人死亡，近 500 人受伤。据一位没有公开发言权的知情人士透露，扎克伯格随后咨询了机器学习应用团队，要求他们采取有效措施，阻止不法分子利用 Facebook 宣传恐怖主义言论。<br/></p>
<p>应用团队利用 Facebook AI 实验室开发的新技术，建立了一个识别社交网络上恐怖主义言论的系统。这个工具能够识别出包含“Islamic State”（伊斯兰国）或“Al Qaeda”（基地组织）字样的主页，标识出了那些最有可能违反公司反恐政策的帖子，并交给审查员审核。<br/></p>
<p>这是 Facebook AI 实验室的一个重要转折点，自此之后他们逐渐将注意力放在利用 AI 技术审查包含不良信息的帖子以及关闭有问题的主页。<br/></p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="0.666992" data-format="jpeg" class="lazyload" src="http://img.qdaily.com/uploads/20190522124038mxpZyU514hoYVwqF.jpg-w600"/><figcaption>Facebook 首席执行官扎克伯格去年在国会作证时表示，他们正在开发基于机器的信息过滤系统，以“识别特定类别的不良活动”。图片版权：Tom Brenner/The New York Times</figcaption> </figure></div>
<p>阻止不良信息传播很快就成了 Facebook 的首要问题。2016 年 11 月，当唐纳德·特朗普成功当选总统时，Facebook 因在其网站上助长虚假信息传播而陷入公关危机，因为这些虚假信息可能对选民产生影响，并为特朗普的获胜奠定了基础。<br/></p>
<p>尽管 Facebook 一直都否认自己在总统选举中扮演了虚假信息传播者的角色，但他们在 2017 年初开始把研究重点放在自动识别不良信息上，并致力于消除情色内容以及打击发布虚假信息的账户。为了过滤网站上的非法内容，他们还专门设立了数十个“诚信”（integrity）职位。<br/></p>
<p>到了 2017 年年中，机器学习应用团队的大部分时间都花在<a href="https://www.nytimes.com/2017/06/15/technology/facebook-artificial-intelligence-extremists-terrorism.html?module=inline" rel="nofollow">检测问题帖子</a>上。施罗普夫说：“在打造 AI 审查系统时，我们把保证网站内容‘阳光正面’作为系统的首要任务。”<br/></p>
<p>2018 年 3 月，《纽约时报》等媒体报道了英国数据分析公司剑桥分析（Cambridge Analytica）在未经数百万 Facebook 用户同意的情况下，<a href="https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html?module=inline" rel="nofollow">暗中收集用户信息</a>，为特朗普团队建立选民档案。一时间，各方矛头直指 Facebook。</p>
<p>施罗普夫临危受命，前往英国平息这场风波。2018 年 4 月，他作为 Facebook 的指定高管飞往伦敦，就剑桥分析丑闻接受英国议会下属委员会的质询。他被烤问了足足四个多小时，国会议员轮番对这家社交网络公司发表了大量批评言论。<br/></p>
<p>“施罗普夫先生，你是否知道何为正直？我不相信贵公司是一家诚信企业。”全世界的观众见证了工党政客伊恩·卢卡斯（Ian Lucas）对这位表情严肃的高管连发质问的画面。<br/></p>
<p>“看着施罗普夫饱受诘难，我实在于心不忍。这就是所谓的任重道远。”虚拟现实初创企业 Pixvana 的首席执行官弗雷斯特·凯伊（Forest Key）说道，他在 1990 年代曾和施罗普夫一起为一家电影特效公司工作。<br/></p>
<p>利用人工智能来过滤不良信息的战役已经正式打响，而施罗普夫自己也陷入了困境。<br/></p>
<h3>劝说工程师不要轻易放弃</h3>
<p>在刚刚加入 Facebook 的时候，施罗普夫就被视为问题解决者。<br/></p>
<p>施罗普夫在佛罗里达州德尔雷海滩（Delray Beach）度过了他的童年。他的父母经营着一家 1000 瓦功率的 AM 电台，专门为听众播放摇滚老歌，后来他们还转换曲调播起了 R&amp;B。他在 1993 年搬到了加州并在斯坦福大学完成学业，本科和研究生专业都是计算机科学。他在斯坦福结识了一批技术专家，其中就有里利以及亚当·纳什（Adam Nash）。纳什目前在文件共享公司 Dropbox 担任高管职位。<br/></p>
<p>毕业后，施罗普夫留在硅谷从事技术工作，他一路披荆斩棘闯出了一番事业。他先是在一家电影特效初创公司开启了自己的职业生涯，后来还成立了一家软件公司，为大型计算机数据中心开发定制软件，这家公司后来被 Sun Microsystems 收购。2005 年，他加入 Mozilla 并担任工程副总裁。当时这家位于旧金山的非盈利机构正在开发一款网络浏览器，以挑战微软及其 IE 浏览器的垄断地位。在那个时候，这类大型开发项目是非常少见的。<br/></p>
<p>“浏览器的开发工作异常复杂，而且外部竞争环境也不是很正常。”曾经与施罗普夫并肩作战的 Mozilla 创始人迈克·谢弗（Mike Shaver）评价道：“即使是在他职业生涯的早期，我也从未怀疑过施罗普夫的能力。”<br/></p>
<p>2008 年，Facebook 联合创始人达斯汀·莫斯科维茨（Dustin Moskovitz）辞去了工程主管的职务，由施罗普夫接替。当时 Facebook 大约有 200 万用户，他的任务是在用户数量激增的情况下保持网站正常运行。他需要管理散布于世界各地的数千名工程师，同时保证数万台服务器正常运作。<br/></p>
<p>他说：“完成这项工作就像驾驶一辆冒着火光、瘪了轮胎的公共汽车滚下山坡一样。我们一直都在试图让这个网站保持正常运转”施罗普夫说，他每天的大部分时间都在“劝说工程师们不要轻言放弃”，因为这些技术人员顶着巨大的压力，无时无刻不在处理着棘手的技术难题。<br/></p>
<p>在接下来的几年时间里，他的团队为 Facebook 量身开发了一系列新技术以便于更好地为庞大的用户群体提供服务。（Facebook 目前拥有 20 多亿用户。）他们还推出了新型编程工具，让 Facebook 能够更快、更可靠地呈现在笔记本电脑和手机上。他们为数据中心引入了定制服务器，简化计算机网络结构。最终，Facebook 显著减少了服务中断事件。</p>
<p>施罗普夫说：“我已经忘记上一次和为了解决这类问题而累到精疲力尽的工程师交谈是什么时候了。”<br/></p>
<p>施罗普夫的努力有目共睹。2013 年，他被提升为首席技术官。他的新任务是着眼于未来，集中精力探索能为公司带来增长的全新技术领域。在 Facebook 总部办公室里，他的桌子位于首席执行官扎克伯格以及首席运营官雪梨·桑德伯格（Sheryl Sandberg）之间，这也表明了他在公司中的地位举足轻重。<br/></p>
<p>“他是公司大部分员工思维方式以及工作方式的典型化身。”扎克伯格在谈到施罗普夫时说。“他的超能力是能够在不同的领域指导并组建团队。我从来没有见过在这方面比他还要出色的管理者。”<br/></p>
<p>因此，当扎克伯格遇到不良信息泛滥问题时，他很自然地向施罗普夫寻求帮助。<br/></p>
<h3>西兰花 VS 大麻花蕾</h3>
<p>最近的一个下午，在 Facebook 会议室里，施罗普夫在他的苹果笔记本电脑上展示了两张照片，一张是碧绿的西兰花，另一张是含苞待放的大麻花蕾。房间里的每个人都好奇地盯着这两张图片，一些人甚至无法“分明正身”。<br/></p>
<p>施罗普夫利用这些照片来表明自己的观点。尽管我们中的一些人很难区分这两种植物，但 Facebook 的人工智能系统目前已经能够在数千张图片中发现特定规律，自动识别出大麻花蕾的图片。这样一来 Facebook 就可以批量识别附加到 Facebook 广告上的大麻图片，从而删除含有大麻买卖信息的帖子。<br/></p>
<p>“我们现在终于可以扭转局面，积极地消灭此类不良信息。”施罗普夫说。<br/></p>
<p>问题是“大麻 VS 西兰花”不仅标志着 AI 过滤系统的识别能力迈上了新的台阶，恐怕也标志着此类技术已经触及极限。施罗普夫团队建立的信息过滤系统现已投入实际使用，它们每天都在识别并删除毒品图片、情色帖子以及恐怖主义相关内容。但这套系统并没有将所有不良信息一网打尽，因为总是会有一些令 AI 系统意想不到的新内容出现，这意味着数百万条包含不良信息的帖子继续毒害着 Facebook 用户。<br/></p>
<p>对于人工智能技术来说，识别图像是一项比较容易完成的任务。真正的难题是开发一套虚假新闻以及仇恨言论的识别系统。在不清楚事实的情况下，就连人类审查员也难以辨别新闻的真假，而自动识别仇恨言论也存在很大的难度，因为机器很难分辨语言上的细微差别，更不用说不同语言之间的语法结构存在巨大的差异，而对话的内容又时时在更新，使得机器难以跟得上狡诈的不法分子。<br/></p>
<p>探索利用 AI 技术来对抗虚假信息的非营利机构——人工智能组织（AI Foundation）研究主管迪利普·拉奥（Delip Rao）将这一挑战描述为“一场军备竞赛”。AI 系统的训练内容通常取自以前的资料。大部分时候研究员并没有现存方案可供借鉴，他们必须根据现实需求发明出新技术。而不法分子又常常改变发帖策略，双方就像在玩一场猫鼠游戏。<br/></p>
<p>拉奥说：“有时候开发人员走在了不法分子的前面，有时候则被甩在身后。”<br/></p>
<p>那天下午，施罗普夫试图运用数据来回答“猫鼠游戏”问题。他说，Facebook 现在能够自动从社交网络上删除 96% 的裸体内容。而仇恨言论问题则比较棘手，他说 AI 系统目前可以识别出 51% 包含仇恨言论的帖子。（<a href="https://www.facebook.com/zuck/posts/10107320597894931?sfnsw=cl" rel="nofollow">Facebook 后来表示</a>，这一比例已升至 65%）<br/></p>
<p>施罗普夫也承认了军备竞赛论。他还表示，能够自动检测并移除不良直播源的 AI 系统在 3 月份没能将新西兰枪击案视频识别为危险内容，因为这与之前上传到 Facebook 上的任何视频都不一样，这段视频以第一人称的视角来展现枪击过程，就像电脑游戏一样。<br/></p>
<p>在设计暴力图像过滤系统时，Facebook 团队通常利用以前的内容来为 AI 系统提供机器学习资料——虐待小猫、恶狗袭击路人、飞驰的汽车撞向行人、挥动棒球拍殴打他人等图像。但是“新西兰枪击案视频却与众不同”。<br/></p>
<p>施罗普夫说，这段视频的惊奇之处就是它引起轰动的原因。“这也解释了为什么直播源没有立即得到标记。”他还补充说，为了更好地了解如何才能有效识别此类视频，他已经反复观看了视频片段。<br/></p>
<p>“我真想从脑海里移除那些可怕的画面。”他说。<br/></p>
<p><br/></p>
<p>翻译：熊猫译社 驰逸</p>
<p>题图版权：Peter Prato/The New York Times</p>
<p>© 2019 THE NEW YORK TIMES</p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>