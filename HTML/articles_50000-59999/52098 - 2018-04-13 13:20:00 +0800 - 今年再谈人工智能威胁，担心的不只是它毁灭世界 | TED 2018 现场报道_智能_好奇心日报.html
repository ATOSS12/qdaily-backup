<h1>今年再谈人工智能威胁，担心的不只是它毁灭世界 | TED 2018 现场报道_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20180412162441jUW63khGf1KS02iX.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://img.qdaily.com/user/face/20190128000025sMDOJ7c5gmklZ60y.JPG?imageMogr2/auto-orient/thumbnail/!80x80r/gravity/Center/crop/80x80/ignore-error/1"/> </a>  <span class="name">龚方毅 温欣语</span><span class="date smart-date" data-origindate="2018-04-13 13:20:00 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2018-04-13 13:20:00</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="52098" data-title="《今年再谈人工智能威胁，担心的不只是它毁灭世界 | TED 2018 现场报道》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20180412162441jUW63khGf1KS02iX.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/52098.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="308"/></a>  </div></div> </div>  <p class="excerpt">在可以直接毁灭人类的人工智能到来前，还有更多迫近的威胁。</p>  <div class="detail">  

<p cid="n51" mdtype="paragraph" nocleanhtml="true">麻省理工学院物理学家马克思·泰格马克（Max Tegmark）不是第一个警告我们人工智能风险的学者，但他可能是比喻用的最好的。</p>
<p cid="n51" mdtype="paragraph" nocleanhtml="true" class="">“不久以前，机器人甚者连走都不会，现在已经可以后空翻了。不久以前，自动驾驶汽车尚未出现，但现在我们已经有可以自己飞回来的火箭了。不久以前，人工智能做不到人脸识别，现在它已经生成虚拟面容……” </p>
<p cid="n51" mdtype="paragraph" nocleanhtml="true" class="">在 TED 大会 2018 的演讲中，&#13;
&#13;
&#13;
泰格马克一个接一个的举着例子，背后的大屏幕上放着波士顿动力的机器狗、SpaceX 的 Falcon 火箭的演示视频。</p>
<div class="com-insert-images"><figure style="margin:0;">&#13;
    <img alt="" data-ratio="0.666875" data-format="jpeg" class="lazyload" src="http://img.qdaily.com/uploads/20180412211442h3jcEiaTlgZ9L64O.jpg-w600"/>&#13;
<figcaption class="">  马克思·泰格马克。图/TED  </figcaption></figure></div>
<p cid="n77" mdtype="paragraph">“科技总是可以为善或者作恶，你得小心处理，小心打造它、小心应用它。” 扎克伯格这句话现在显得格外应景。</p>
<p cid="n90" mdtype="paragraph">泰格马克没有直接给出答案，而是试图让现场观众思考他们希望看到什么样的未来。他提出生命 3.0（Life 3.0，<a href="http://admin.qdaily.com/admin/articles/54366/medium_editor">也是他新书的名字</a>）的概念。按照他的逻辑，1.0 是原始生命诞生，如细菌。生命在这个过程中就是不断复制。</p>
<p><img data-format="jpg" data-ratio="0.380009" class="lazylaad lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124630Jo20tv7p63SFNTHe.jpg-w600"/></p>
<p cid="n90" mdtype="paragraph">2.0 是人类学习、发明、创造的过程，不同族群有各自的语言、文化。如果把躯干比作硬件，知识比作软件，人类在生命 2.0 阶段学会创造软件，在 3.0 则是创造硬件。“当然 3.0 并不存在。但应用技术已经让我们达到生命 2.1 阶段，”台上的泰格马克一边演讲一边指着自己的膝盖和胸口说道，“比如人工关节、心脏起搏器、助听器等等。”</p>
<p cid="n90" mdtype="paragraph" class="">那么未来，人工智能可以走得多远？除了照例能听到的关于就业市场，隐私和大规模杀伤性武器的熟悉讨论，泰格马克用下面这张图作比喻：</p>
<div class="com-insert-images"><figure style="margin:0;">&#13;
    <img alt="" data-ratio="0.519660" data-format="png" class="lazyload" src="http://img.qdaily.com/uploads/20180412202503aCQ1BdXxAmouM0Pj.png-w600"/>&#13;
<figcaption class="">人工智能实现程度是海平面，一个个岛屿山川代表难易度。最终人工智能海平面会像全球变暖最终结果那样，淹没现有的一切。</figcaption></figure></div>
<p cid="n90" mdtype="paragraph" class="">图里的岛屿、山脉是一项项跟人工智能有关的技术应用，海拔高低代表技术实现的难易程度。翻译、自动驾驶、围棋、语音识别所在的岛屿基本刚高出海平面，这也是目前人工智能最主要的应用领域。</p>
<p cid="n90" mdtype="paragraph" class="">而艺术、摄影、写书、理论认证等暂时都还是高山，代表人工智能尚难驾驭的领域。现在一种普遍观点是，人工智能可以做更多程式化、模板化的工作，但精神创造、艺术文化等方面还是人类更擅长。</p>
<p cid="n90" mdtype="paragraph" class="">“不过最终，代表人工智能实现程度的海平面还是淹没一切。人工智能达到这个高度时，其实已经是通用人工智能（AGI）。”&#13;
&#13;
&#13;
&#13;
泰格马克说。通用人工智能大概是能和人类一样思考和学习，能够举一反三，甚至产生独立意识、再进化出更高级的人工智能 —— 超级人工智能。</p>
<div class="com-insert-images"><figure style="margin:0;">&#13;
    <img alt="" data-ratio="0.518008" data-format="png" class="lazyload" src="http://img.qdaily.com/uploads/20180412205809R4j1sLlh6i8xS2wA.png-w600"/>&#13;
<figcaption class="">通用人工智能（AGI）淹没一切。</figcaption></figure></div>
<p cid="n90" mdtype="paragraph" class="">只是现在没人能说得清这个虚无缥缈的东西。它可能是《终结者》系列电影里可以发射核弹，奴役人类的“天网”；也可能是你下一道命令、说“预测一下战争的走向”，接下来这个 AI 从互联网上检索内容，分析将领的性格，新闻的趋势，经济情势的变化，历史上类似战例的结果，最后在一秒内得出一个报告。</p>
<p cid="n90" mdtype="paragraph" class="">去年，包括不少科学家和大科技公司创始人都曾谈到过“超级人工智能”。&#13;
&#13;
硅谷孵化器 YC 的主席、跟马斯克一起创办了 OpenAI 的萨姆·奥特尔曼觉得，人工智能的研究很可能方向完全错了，也有可能就差一个算法了，很多人都相信超级智能是危险的，但觉得离得很远，可能永远不会发生，但“这想法真的草率又危险”。</p>
<p cid="n90" mdtype="paragraph" class="">不过一小部分参加 TED 大会的人不介意今后的生活由机器决定：</p>
<div class="com-insert-images"><figure style="margin:0;">&#13;
    <img alt="" data-ratio="0.510074" data-format="png" class="lazyload" src="http://img.qdaily.com/uploads/201804131129488vZkROIcK1eHPBCJ.png-w600"/>&#13;
<figcaption class="">泰格马克在 TED 做了问卷调查，看大家是否愿意被机器统治。图中橙色那部分人代表愿意。图/TED</figcaption></figure></div>
<p cid="n90" mdtype="paragraph" class="">泰格马克则觉得，超级人工智能的真正风险不在于它是否具备恶意，而是它将非常善于实现其目标，如果这些目标与人类的目标不一致，人类就会陷入困境。</p>
<p cid="n90" mdtype="paragraph" class="">他举了非洲黑犀牛灭绝的例子：人类不是邪恶、无知到希望黑犀牛灭绝，而是作为更聪明的物种，人类获得犀牛角的目标和黑犀牛求生的目标不一致。在不断的差异碰撞中，更弱势的一方逐渐消亡。</p>
<p cid="n90" mdtype="paragraph" class=""> “我们要尽量避免今后人类处在如今黑犀牛的位置上。”泰格马克说。<br/></p>
<p cid="n90" mdtype="paragraph" class="">从现有的研究和预测看，人工智能将来几乎一定会在多个领域比人类更出色，那么人类与超级人工智能共处时，也可能会面临黑犀牛的遭遇。</p>
<p cid="n90" mdtype="paragraph" class="">他提到载人火箭发射任务成功前，绝大多数人觉得把人绑在一堆爆炸燃料、射到一个出了问题没人能帮上忙的地方，怎么看都不对。</p>
<p cid="n90" mdtype="paragraph" class="">“在麻省理工有个说法叫安全工程。它的设计越安全，任务成功率就越高，”泰格马克说，“这也是我们我们对待人工智能的态度：做最坏的打算，然后确保事情往对的方向发展。”</p>
<p cid="n90" mdtype="paragraph" class="">但这又会产生新的问题。&#13;
&#13;
泰格马克谈到人类想限制超级人工智能、仅为自己所用，这就像在禁锢上帝，如果有一天我们不再有能力驾驭、“上帝”逃了出来并接管人类社会，没人知道它会是跟人类价值观相同的新生命体，还是毫无意识为所欲为的僵尸（zombie）。</p>
<p cid="n90" mdtype="paragraph" class="">在今年 TED 大会第一天的演讲中，&#13;
&#13;
杜比实验室的首席科学家<font color="#333333">波比·克伦（<a href="https://www.linkedin.com/in/poppy-crum-9792298" rel="nofollow"/></font><a>Poppy Crum</a><font color="#333333">）谈到<a href="http://www.qdaily.com/articles/52068.html">另一种人工智能的威胁</a>。</font></p>
<p cid="n90" mdtype="paragraph" class=""><font color="#333333">现在</font>越来越多的传感器可以让人获取海量数据，检测到脸部温度的变化、捕捉你用词的变化、捕捉到你的眼部运动……愈发进步的人工智能自己就能在海量数据里找到规律，科技公司、广告公司甚至政府机构可以毫不费力的知道你在想什么、喜欢什么、是否撒谎。那么技术的边界在哪里？</p>
<p class=""><span style="color: rgb(51, 51, 51);">“同样的技术很多时候可以帮助我们。我觉得我们也确实想知道自己的真实想法，”克伦说，“我们需要意识到各种组织、政府能怎样用这些技术，这样才能保护我们。”</span><br/></p>
<p class=""><span style="color: rgb(51, 51, 51);">但有的时候不需要新数据，人工智能的能力也已经足够让人害怕。</span>泰格马克提到人工智能可以生产虚拟面容，也就是假脸，实际就是<font color="#333333">利用</font>现有的视频资料为基础，来匹配人类说话的语音和嘴形。</p>
<p class="">做这个研究的是 Google 工程师 <a href="http://grail.cs.washington.edu/projects/AudioToObama/siggraph17_obama.pdf" rel="nofollow">Supasorn Suwajanakorn</a>，他站在 TED 标志性的圆形红毯上时，身后的屏幕上显示了 4 个奥巴马正在说话的视频。他让台下的观众猜，哪一个是真正的奥巴马？</p>
<div class="com-insert-images medium-insert-active"><figure style="margin:0;">&#13;
    <img alt="" data-ratio="0.666667" data-format="jpeg" class="lazyload" src="http://img.qdaily.com/uploads/20180413124855tLC6xSXIspageWi1.jpg-w600"/>&#13;
<figcaption class="">这些视频看起来真的像是奥巴马正在演讲，但实际上没有一个是真的奥巴马。  </figcaption></figure></div>
<p>没有一个奥巴马是真的。Suwajanakorn 一共在视频里让 9 个世界政要，包括老布什、希拉里、奥巴马、安倍等，说同一句话。</p>
<p class="">这不加剧假新闻的泛滥？&#13;
&#13;
Suwajanakorn 会告诉你一个更好听的故事。他希望这项技术能让那些已过世但对人类有巨大贡献的人重新活过来，对着人们说话。比如莎士比亚为你朗读一首诗，比如过世的祖母对你说话。</p>
<p class="">“我们希望用这样的技术去激发小孩，”Suwajanakorn 说。<br/></p>
<p>不过对于大多数在座的听众来说，看到这些视频的第一反应是“恐怖”。Suwajanakorn 演讲结束后被提问如何防止这项技术被滥用，他给出的答案很标准，“我们是工程师，我们能研究出一项技术，就能做逆向工程，” 目前他的逆向工程可以迅速在网页界面辨认出网站是否是假新闻，高亮出假新闻网站。</p>
<p>结尾他又回到了 Google 的那套不作恶的说辞，“我们一定会非常小心使用技术，不会滥用。”这话之前扎克伯格也说过。</p>
<p class=""><br/></p>
<p class="">题图/TED<br/></p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>