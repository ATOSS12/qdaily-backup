<h1>你看到的新闻不一定是真的，视频也不一定是：假视频来了_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20180306180908CPpae6YFVBNT3Hn4.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://m.qdaily.com/images/missing_face.png"/> </a>  <span class="name">Kevin Roose</span><span class="date smart-date" data-origindate="2018-03-07 07:37:21 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2018-03-07 07:37:21</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="50857" data-title="《你看到的新闻不一定是真的，视频也不一定是：假视频来了》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20180306180908CPpae6YFVBNT3Hn4.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/50857.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="436"/></a>  </div></div> </div>  <p class="excerpt">我们能做的，或许只能是在假货产生时将其制止，迫使社交媒体公司更加积极地打击虚假信息，并对我们的所闻所见保留更多的疑问。</p>  <div class="detail">  

<p><strong><em>＊<a href="https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html">本文</a>只能在《好奇心日报》发布，即使我们允许了也不许转载＊</em></strong></p>
<p>画面开始，房间里摆放着红色沙发、盆栽植物，以及治疗师墙上常见的那种索然无味的现代艺术画。<br/></p>
<p>房里坐着的是米歇尔·奥巴马（Michelle Obama），或是一个跟她一模一样的人。低胸上衣里边的黑色胸罩清晰可见，她在镜头前卖力地扭动，笑容里的含义不言而喻。<br/></p>
<p>之后，这位前第一夫人的“分身”开始脱衣服。<br/></p>
<p>这种出现于在线论坛 Reddit 的视频是一种通过人工智能软件制作、效果超级逼真的假视频，名为“deepfake”。它基于一种名为 FakeApp 的程序创建，将奥巴马夫人的面容合成在一个色情演员的身体上。混合之后的效果实在不可思议，如果你不知道真相，很可能会认为那真的就是前总统夫人。<br/></p>
<p>不久前，通过计算机制作出逼真的视频还是件很费力的追求，仅限于预算充沛的好莱坞影视公司或尖端科研人员。Snapchat 之类的社交媒体应用所采用的则是一些初级人脸变形技术。<br/></p>
<p><img data-format="jpg" data-ratio="0.37666" class="lazylaad lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124612v5wnh60OmgCAUPGJ.jpg-w600"/></p>
<p>但在最近几个月，一个视频爱好者社区已经开始尝试更为强大的工具，其中就包括匿名开发者通过谷歌开源软件建立的 FakeApp 程序。FakeApp 可以免费使用，而且容易实现逼真的面部互换，几乎没有任何造假痕迹。这款程序的开发者表示，自从一月份发布到 Reddit 后，它的下载量已超过 12 万次。<br/></p>
<p>Deepfake 视频是一种最新形式的数字媒体处理产品，显然也是最容易用来恶搞的。不难想象，这种技术可用于抹黑政客、伪造报复性色情内容，甚至陷害他人入罪。立法者已经<a href="http://thehill.com/policy/technology/374320-lawmakers-worry-about-rise-of-fake-video-technology">开始担心</a>，这种视频可能被用于政治阴谋和虚假宣传。<br/></p>
<p>即便是在 Reddit 这类不怎么讲究道德的网站，deepfake 视频也引起了公愤。FakeApp 最近还导致了大规模恐慌：技术网站 Motherboard <a href="https://motherboard.vice.com/en_us/article/gydydm/gal-gadot-fake-ai-porn">报道称</a>，有人用它来制作知名人物的 deepfakes 色情视频。随后，Pornhub、Twitter 和其它网站在第一时间<a href="http://variety.com/2018/digital/news/reddit-twitter-deepfake-ban-1202690627/">屏蔽了这些视频</a>。而 Reddit 则关闭了几个 deepfake 群组，其中一个拥有近 10 万名成员。<br/></p>
<p>在 Reddit 关闭 deepfake 群组之前，这些成员曾举办了分享会，让用户交流视频编辑技巧并展示最新的假视频。在一篇题为《从更多角度进行三维人脸重建》的帖子旁，就是一则名为《（不是）奥利维亚·王尔德（Olivia Wilde）在自慰》视频。<br/></p>
<p>有些 Reddit 用户为 deepfake 视频鸣不平，指责媒体对它的潜在危害言过其实。因为坚信 Reddit 会根据相关规则，极力制裁非合意的色情内容，有些用户选择把视频转移到别的平台。还有一些人在道德上对这种技术的出现深感不安。<br/></p>
<p>之后，用户仍在源源不断地制造更多作品。<br/></p>
<p>Deepfake 的制作者社区目前躲在互联网的阴暗角落里。但事情曝光之后，公众对此极为不安，因为它给未来蒙上了一层阴影。<br/></p>
<p>一位 Reddit 用户写道：“这简直可以拍成一集《黑镜》（Black Mirror）了。”这篇帖子对 deepfake 的本质提出了本体论问题：如果将人物乙的脸庞以真实、不露痕迹的方式叠加在人物甲的脸上，人物甲的裸体图片是否就会变成人物乙的？从广义而言，在互联网上，表象和现实之间有何区别？<br/></p>
<p>这个用户在注销前满不在乎地写道：“祝叛逆者们好运。”</p>
<h3>制作 Deepfake</h3>
<p>在 Reddit 的 deepfake 社区潜伏几个星期之后，我决定用自己的脸做个试验，看看创建一个 deepfake 有多么容易（考虑到工作，不搞色情的）。<br/></p>
<p>首先，我下载了 FakeApp 并找了两个技术专家帮忙。一个是《纽约时报》研发部门的同事马克·麦基格（Mark McKeague），另一个是我在 Reddit 上找到的一个 deepfake 制作者，昵称是 Derpfakes。<br/></p>
<p>鉴于 deepfake 作品具有巨大的争议性，Derpfakes 不愿透露自己的真名。Derpfakes 从几周前<a href="https://www.youtube.com/channel/UCUix6Sk2MZkVOr5PWQrtH1g">开始在 YouTube 上发布</a> deepfake 视频，以幽默类为主，比如让尼古拉斯·凯奇扮演超人。该账号还发布过一些 deepfake 视频创作教程。<br/></p>
<p>我所学到的是：制作一个 deepfake 并非轻而易举，但也没有让火箭上天那么难。<br/></p>
<p>第一步是找到或租用一台普通性能的电脑。Fakeapp 使用的是一套名为 TensorFlow 的机器学习工具，它由 Google 人工智能部门开发并于 2015 年向公众开放使用。这款软件能够自主学习，<a href="https://www.nytimes.com/interactive/2018/01/02/technology/ai-generated-photos.html">通过反复试验</a>来完成图像识别任务。电脑的处理能力越强，工作速度就越快。<br/></p>
<p>为了提高速度，我和马克通过 Google 云平台租用了一台远程服务器。它的处理能力极为强大，可把时间缩短到几个小时，如果用我的笔记本电脑，可能需要几天甚至几周。<br/></p>
<p>当马克安设好远程服务器，并在上边加载了 FakeApp 之后，我们就可以进行下一个步骤：数据采集。<br/></p>
<p>选择正确的源数据至关重要。与长视频相比，短视频剪辑更容易操作，单角度拍摄的场景比多角度拍摄的结果要更好。遗传也是一大因素：脸越像，效果就越好。<br/></p>
<p>我是一个留着短须、头发棕色的白人，所以马克和我决定尝试变成其他棕色头发、留着胡茬的白人。我们决定首先从瑞恩·高斯林（Ryan Gosling）入手。（目标够高的吧？）我也向那位来自 Reddit 的技术外包专家 Derpfakes 发送了几个视频，从中进行选择。<br/></p>
<p>接下来，我们给我的面部拍了几百张照片，然后从最近的电视节目上剪辑了一些高斯林的面部图片。FakeApp 使用这些图片来训练深度学习模型，教它模仿我们的面部表情。<br/></p>
<p>为了尽可能获得更多的图片源，我以不同角度扭动头部，尽量做出各类迥异的表情。</p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="0.987500" data-format="gif" class="lazyload" src="http://img.qdaily.com/uploads/2018030617594742qSJsKadwPrb1Oj.gif-w600Gif"/> </figure></div>
<p>在这之后，马克用一个程序裁剪这些图像，只留下我们的面部，并手动删除任何模糊或质量不佳的图片。然后将它们导入 FakeApp。我们总共用了 417 张我的照片，以及 1113 张高斯林的照片。<br/></p>
<p>图像准备完毕后，马克按下 FakeApp 的开始键，机器训练就此开始。他的电脑屏幕满是高斯林和我的脸，这时程序正在试图识别脸型和相似性。<br/></p>
<p>约 8 小时后，我们的模型已得到充分训练，马克用 FakeApp 把我的脸放在高斯林的身上。视频既模糊而又离奇，高斯林的脸会偶尔出现。只有彻彻底底的盲人才会把视频中的高斯林错认为我。<br/></p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="0.553125" data-format="gif" class="lazyload" src="http://img.qdaily.com/uploads/20180306180014iP6qeW1T2IHvyXsO.gif-w600Gif"/> </figure></div>
<p>我们在《侏罗纪世界》（Jurassic World）的主演克里斯·帕拉特（Chris Pratt）身上取得了更好的效果，这个不修边幅的明星有着跟我更为类似的脸型。为了此次测试，马克使用了一个更大的数据集，其中包括 1861 张我的照片和 1023 张帕拉特的照片，并让模型彻夜运行。<br/></p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="0.553125" data-format="gif" class="lazyload" src="http://img.qdaily.com/uploads/20180306180028H2fNYhnyjm3c9sJM.gif-w600Gif"/> </figure></div>
<p>几天后，Derpfakes 也训练了一个模型，根据我发给他的视频和演员杰克·吉伦哈尔（Jake Gyllenhaal）的镜头制作了 deepfake 视频。这个视频把我的五官与他的头发、胡须和身体融合到一起，效果更加逼真，简直栩栩如生。<br/></p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="0.553125" data-format="gif" class="lazyload" src="http://img.qdaily.com/uploads/20180306180049hU3EzHA4NJWOm1vf.gif-w600Gif"/> </figure></div>
<p>Derpfakes 还使用了吉米·坎摩尔（Jimmy Kimmel）和列维·施瑞博尔（Liev Schreiber）的视频不断重复训练过程，得出的视频效果也非常好。作为一个经验丰富的 deepfake 制作者，Derpfakes 的感觉更为敏锐：知道哪种视频源制成的作品会有更好的效果，对在 deepfake 的完工阶段进行细微的调整和混合也更有经验。<br/></p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="0.553125" data-format="gif" class="lazyload" src="http://img.qdaily.com/uploads/20180306180124V6rizB7obPq9mnxM.gif-w600Gif"/> </figure></div>
<p>我们的 deepfake 实验共历时 3 天，在 Google 云计算平台上花费了 85.96 美元。对于做明星梦而言，这个代价不算大。<br/></p>
<h3>来自应用开发者的话</h3>
<p>实验结束后，我通过网站上的电子邮件地址联系到了 FakeApp 匿名开发者。我想知道他/她的观点：创造一个尖端的人工智能工具，难道仅仅是为了聚拢一群色情作品作者，让他们可以兴高采烈地挑战伦理道德吗？<br/></p>
<p>一名男子回了信，称自己是马里兰州的一名软件开发人员。跟 Derpfakes 一样，他不愿透露真实姓名，仅用名字首字母“N”自称。他表示，创造 FakeApp 的初衷是作为一种创意实验，现在却眼睁睁看着 Reddit 的 deepfake 社区在滥用它。这让他觉得很懊恼。<br/></p>
<p>“我是因为这些算法加入这个社区的，当时人数很少（不到 500 人），”他写道，“当我看到结果时，我就知道这是一项优秀的技术，应该推广给任何想使用它的人。我想我应当尝试一下，就把它弄成了一个易于使用的软件包。”<br/></p>
<p>N 表示，他不支持将 FakeApp 用于创建非合意色情或其它不良内容。他还同意 Reddit 关于禁止任何明显是 deepfake 内容的决定。但是，他仍要为这个产品辩护。<br/></p>
<p>“我已经反复考虑过了，”他说，“而我最终还是认为不应当谴责技术本身——显然，技术可以用于多种目的，无论好坏。”<br/></p>
<p>FakeApp 使用起来有些繁琐也不容易上手，但这些缺点显然很快就能得到改善。N 表示，FakeApp 在未来可由各种各样的人士使用，让他们的个人作品也能拥有那种需要大笔预算才能达到的特效。<br/></p>
<p>他补充道，深度学习算法在未来将变得极为重要，因为它不仅仅是独立的应用程序，还构成了许多高科技产品的强大组件。<br/></p>
<p>“正是这些事物，让他们变得强大无比、不可或缺，甚至令人胆战心惊，”他说，“只需一点点想象力，你就可以将它应用在任何场合。”<br/></p>
<h3>“下一代沟通形式”</h3>
<p>在上个月佛罗里达州帕克兰发生枪击案当天，一则 BuzzFeed 新闻的截屏在社交媒体上广为流传。这篇文章以“为什么我们比之前任何时候更需要立刻收走白人的枪”为题，作者是一位名叫 Richie Horowitz 的记者。<br/></p>
<p>整件事都是假的。BuzzFeed 并没有一个名为 Richie Horowitz 的员工，<a href="https://www.snopes.com/buzzfeed-white-people-guns/">也从未在网站上发布这个标题</a>。但篡改的图像激起了右翼人士的愤慨，并得到 Twitter 上激进分子的进一步推广。它并非是人工智能产生的 deepfake，甚至都不是一个特别先进的修图技术，但它确实成功了。<br/></p>
<p>无论网上的虚假信息是否包装得光鲜亮丽，当它们进入我们的社交网络后，就会通过一种熟悉的套路流传开来。假新闻会得到 5 万次分享，可 1 小时后别人发的辟谣消息只会获得 200 次分享。在网站算法的帮助下，这群“嘉年华上的狂欢者”在 Facebook 和 Youtube 等平台上大获关注；与此同时，专业人士大声疾呼，却应者寥寥。<br/></p>
<p>我们没理由相信 deepfake 视频会和虚假信息有什么不同。人们在高兴时会分享它们，不高兴时就不理它们。被《洋葱报》（The Onion）的讽刺报道所糊弄的笨蛋同样也会被 deepfake 牵着鼻子走，而关注真相、心思细密之人总会想方设法找出疑点并将其拆穿。<br/></p>
<p>南加州大学计算机科学系助理教授、Pinscreen 创始人 Hao Li 说：“我们别无选择。”他还表示，人工智能的武器化将不可避免，需要让公众意识立刻发生转变。Pinscreen 是一个利用人工智能创建仿真三维头像的公司。<br/></p>
<p>“我把它视为下一代沟通形式，”他说，“我担心人们会用它敲诈别人或者做坏事。你必须告诉人们，这些都是可能发生的后果。”<br/></p>
<p>既然如此，好吧。现在，由我来告诉你：有一个——足以让米歇尔·奥巴马变成色情明星，或将一个其貌不扬的报纸专栏作家转型为杰克·吉伦哈尔的——人工智能就潜伏在我们身边。由它处理过的视频将很快变得随处可见。<br/></p>
<p>我们能做的，或许只能是在假货产生时将其制止，迫使社交媒体公司更加积极地打击虚假信息，并对我们的所闻所见保留更多的疑问。<br/></p>
<p>祝叛逆者们好运。<br/></p>
<p><br/></p>
<p>翻译：熊猫译社 莫云鹏</p>
<p>题图为《夜行者》剧照，来自<a href="https://movie.douban.com/photos/photo/2204157862/">豆瓣电影</a></p>
<p>© 2018 THE NEW YORK TIMES</p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>