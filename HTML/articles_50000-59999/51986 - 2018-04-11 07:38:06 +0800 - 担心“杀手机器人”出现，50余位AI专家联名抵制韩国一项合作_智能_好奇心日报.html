<h1>担心“杀手机器人”出现，50余位AI专家联名抵制韩国一项合作_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/2018041107460223BApTYEWf0Xnse5.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://img.qdaily.com/user/face/20180403082029efZktxmSj5X4vwA0.jpeg?imageMogr2/auto-orient/thumbnail/!80x80r/gravity/Center/crop/80x80/ignore-error/1"/> </a>  <span class="name">丰景</span><span class="date smart-date" data-origindate="2018-04-11 07:38:06 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2018-04-11 07:38:06</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="51986" data-title="《担心“杀手机器人”出现，50余位AI专家联名抵制韩国一项合作》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/2018041107460223BApTYEWf0Xnse5.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/51986.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="49"/></a>  </div></div> </div>  <p class="excerpt">“如果潘多拉盒子被打开，它将很难关闭”。</p>  <div class="detail">  

<p finallycleanhtml="true" nocleanhtml="true">据 <a href="https://www.dezeen.com/2018/04/09/ai-experts-condemn-killer-robots-kaist-south-korea/" rel="nofollow">dezeen </a>报道，机器人领域 50 多名顶尖专家呼吁抵制韩国科学技术研究院（下文简称 KAIST），因为他们担心 KAIST 与国防制造商韩华公司之间的合作会加速自动化武器，也就是“杀手机器人”的发展。<br/></p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="0.562793" data-format="jpeg" class="lazyload" src="http://img.qdaily.com/uploads/20180410140333mhjP0fCpaBt3FYwR.jpg-w600"/><figcaption><p>图片/dezzen</p></figcaption> </figure></div>
<p>KAIST 曾与韩华公司在 2 月 20 日达成合作，建立了 KAIST 国防与人工智能融合研究中心。据 <a href="http://www.sciencemag.org/news/2018/04/korean-university-s-ai-work-defense-contractor-draws-boycott&amp;prev=search" rel="nofollow">Science</a> 报道，该中心主要从事人工智能决策系统的开发，并将其用于飞机训练、追踪识别等技术。</p>
<p>但专家们认为，该研究可能会被应用于自动化武器的研发，其中包括无人驾驶飞机、潜艇、巡航导弹，甚至是战场上的“杀手机器人”。因此，KAIST 与韩华公司的合作会加速军备竞赛和 AI 武器的制造，甚至还可能引发继火药、核武器之后的“第三次战争革命”。</p>
<p>声明中说：“它们会让战争的速度更快，规模也更大。” “他们有可能被恐怖分子利用对抗无辜民众，消除任何道德限制。如果潘多拉盒子被打开，它将很难关闭”。<br/></p>
<p>为此，他们以强硬态度抗议 KAIST 的这一行为：“我们将抵制所有与 KAIST 任何部门的合作，直到 KAIST 的总裁提供保证，该中心不会开发缺乏人类控制的自动化武器”。<br/></p>
<p>但 KAIST 在几小时后否定了这种说法，并回复说：KAIST 不打算参与开发致命的自主军事系统和杀手机器人，“我们很清楚应用包括 AI 技术时的道德界限”。</p>
<p><img data-format="jpg" data-ratio="0.415928" class="lazylod lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124606JSpdaCk3eAlgqD5x.jpg-w600"/></p>
<p>不可否认的是，自动化应用对军事渗入愈加明显：据 <a href="http://time.com/5230567/killer-robots/" rel="nofollow">TIME</a> 称，中国在两年前已在海、陆、空各个领域测试了无人技术；韩国也在 12 月宣布开发应用于战争的无人机群；以色列目前已具备自主式武器，可以在没有人类指挥的情况下俯冲轰炸雷达信号。</p>
<p>它得出的结论是：世界上强大的国家已开始秘密的军备竞赛，而监管机构动作落后。</p>
<p>与此同时，人类与机器间的决策界限也在被广泛讨论。对于自动化趋势，即使掌握了先进技术的国家对日后发展方向也并不明晰。</p>
<p>新美国安全中心的 Paul Scharre 在接受 <a href="http://www.sciencemag.org/news/2018/04/korean-university-s-ai-work-defense-contractor-draws-boycott&amp;prev=search" rel="nofollow">Science </a>采访时表示：”许多国家，特别是机器人领域的领先开发商，对于他们自主权要走多远的规划其实非常模糊。人与机器之间决策权的界限在哪里？ 我们是否愿意将致命的权力委托给这些机器呢？”<br/></p>
<p>题图/《钢铁侠3》来自<a href="https://img1.doubanio.com/view/photo/raw/public/p1753861407.jpg" rel="nofollow">豆瓣</a></p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>