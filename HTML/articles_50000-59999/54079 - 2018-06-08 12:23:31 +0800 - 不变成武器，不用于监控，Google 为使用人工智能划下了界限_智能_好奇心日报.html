<h1>不变成武器，不用于监控，Google 为使用人工智能划下了界限_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20180608100508kBcUJ4KIL1NvjfGW.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://img.qdaily.com/user/face/20170704130846HwXelL5krx8psIim.jpg?imageMogr2/auto-orient/thumbnail/!80x80r/gravity/Center/crop/80x80/ignore-error/1"/> </a>  <span class="name">罗骢</span><span class="date smart-date" data-origindate="2018-06-08 12:23:31 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2018-06-08 12:23:31</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="54079" data-title="《不变成武器，不用于监控，Google 为使用人工智能划下了界限》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20180608100508kBcUJ4KIL1NvjfGW.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/54079.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="121"/></a>  </div></div> </div>  <p class="excerpt">“强大的技术对其使用提出了同等重要的问题。”</p>  <div class="detail">  

<p finallycleanhtml="true">6 月7 日晚上，Google CEO Sundar Pichai <a href="https://blog.google/topics/ai/ai-principles/?utm_campaign=digest&amp;utm_medium=email&amp;utm_source=nuzzel" rel="nofollow">在官方播客上发布文章</a>，回应了最近引起争议的 Google 人工智能武器化的问题。</p>
<p>皮蔡（Pichai）在文中亮明了 Google 对于人工智能技术使用的原则，包括了 7 条人工智能应该努力的目标以及 4 个 Google 不会将人工智能技术使用的方向。</p>
<p>在这篇名为《Google 人工智能：我们的原则》的博文最开始，皮蔡写到：“强大的技术对其使用提出了同等重要的问题。人工智能如何开发和使用，将会对未来多年的社会产生重大影响。”</p>
<p>然后他公布了 Google 7 项人工智能指导原则：<br/></p>
<p><strong>Google 相信人工智能技术应用的目标：</strong></p>
<p><img data-format="jpg" data-ratio="0.417342" class="lazylaad lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124630Jo20tv7p63SFNTHe.jpg-w600"/></p>
<ol>
<li>对社会有益；<br/>人工智能的进步将对包括医疗保健，安全，能源，运输，制造和娱乐在内的各种领域产生革命性的影响。所以人工智能技术在发展的过程中应该考虑到帮助社会的因素，同时还应该考虑对不同社会的文化，法律准则。<br/>
</li>
<li>避免制造或加剧偏见；<br/>用算法来区分公平和不公平的偏见并不是一件简单的事情，并且在不同的文化和社会中也有很多不同。Google 将努力避免对人工智能技术因为种族，民族，性别，国籍，收入，性取向等内容造成不公正的影响。<br/>
</li>
<li>提前测试以保证安全；<br/>Google 将谨慎地开发最新的人工智能技术，并加入更多的监测等安全措施。<br/>
</li>
<li>由人类担责；<br/>Google 的人工智能技术将受到一定程度人类的指导和控制。<br/>
</li>
<li>保证隐私；<br/>Google 将把隐私原则融入人工智能技术的开发和使用，将向用户提供通知和申请同意的提示，鼓励具有隐私保护措施的架构，并对数据的使用提供适当的透明度和控制。<br/>
</li>
<li>坚持科学高标准；<br/>
</li>
<li>从主要用途、技术独特性、规模等方面来权衡。</li>
</ol>
<p>比起目标，更重要的是，Google 也正式申明将不会把人工智能技术用于武器以及大规模监控。</p>
<p><strong>Google 申明不会将人工智能技术应用于：</strong></p>
<ol>
<li>制造整体伤害之处。如一项技术可能造成伤害，我们只会在其好处大大超过伤害的情况下进行研发，并提供安全保护措施；<br/>
</li>
<li>武器或其他用于直接伤害人类的产品；<br/>
</li>
<li>收集使用信息，以实现违反国际规范的监控的技术；<br/>
</li>
<li>目标违反被广泛接受的国际法与人权原则的技术。<br/>
</li>
</ol>
<p>皮蔡表示，7 项原则和 4 个不会并不是理论和概念，而是具体的标准。并且会直接来指导 Google 今后的工作，产品的研究和开发，并会影响 Google 的业务决策。</p>
<p>皮蔡的回应是因为去年 Google 和美国军方五角大楼合作 Project Maven 项目，这个项目中 Google 为军用无人机开发人工智能技术而引起公司内部巨大的争议风波。</p>
<p>这个来自于五角大楼的 Maven 项目成立于 2017 年 4 月，当时宣称的目标就是“加速国防部整合大数据和机器学习的能力”。<a href="https://www.wsj.com/articles/the-new-arms-race-in-ai-1520009261" rel="nofollow">《华尔街日报》报道称</a>，国防部总共在 2017 年花费了 74 亿美元用于人工智能技术等相关领域。<br/></p>
<p>其中 Google 使用机器学习和人工智能技术来识别无人机镜头中的车辆和其他物体，从而减轻分析人员的负担，最终则能够在无人机拍摄时进行自动检测和识别追踪指定物体。<br/></p>
<p>随着消息的曝光，这个计划引发了大量 Google 员工们对于人工智能技术用于战争的担忧。有近 4000 名 Google 员工在今年 4 月的内部<a href="https://static01.nyt.com/files/2018/technology/googleletter.pdf" target="_blank" rel="nofollow">请愿书中</a>表示反对 Maven 项目，要求 Google 立即停止合作并制定新政策，以防止未来再次参与军事任务。</p>
<p>同时十余名 Google 员工通过辞职抗议 Google 与美国国防部的合作。当时，Google 公司的发言人为 Maven 项目进行了辩护，虽然承认把人工智能技术用于军事目的是“存在争议性的”，但他强调机器学习技术只涉及“非杀伤性用途”，并表示 Google 目前正在围绕这项技术制定政策和保障措施。<br/></p>
<p>6 月 4 日，Google 宣布不再续约参与军事人工智能研发。随后在今天，Google CEO Sundar Pichai 公布了人工智能使用原则。</p>
<p>曾经，“Don’t be evil”一直是 Google 非正式的座右铭，也写入了公司行为准则的开头。“我们有‘不作恶’（Don’t be evil）的信条，要为我们的用户、客户和每一个人，做我们所知的最好的事情，”2004 年，Google 联合创始人拉里·佩奇（Larry Page）对 ABC 电视台主播彼得·詹宁斯说了这么一番话。<br/></p>
<p>但上个月，Google 将 Don’t be evil <a href="http://www.documentjournal.com/2018/06/google-quietly-abandons-emphasis-on-their-dont-be-evil-motto/" rel="nofollow">从自己的行为准备中拿掉了</a>，只在准则的最末尾提到了一句。这也引起了 Google 员工质疑公司行为准则的讨论。</p>
<p>随着周四，皮蔡代表公司亮明了态度。Google 云 CEO 戴安·格林（Diane Greene）也<a href="http://www.businessinsider.com/google-diane-greene-honor-military-contract-no-follow-ons-2018-6" rel="nofollow">在官方博客上发布了一篇文章</a>，来介绍如何在 Google Cloud 业务上执行 Google的 AI 原则。</p>
<p>她特别提到，Google 将不再延续和军方的 Project Maven 合同。仅仅是在网络安全、新兵招募以及搜救行动等其他内容上保持合作。</p>
<p>而 Google 现任人工智能负责人 Jeff Dean 在 Twitter 上分享 Google 发表的这份原则之后，还提到为了真正践行这些原则，Google 提出了<a href="https://ai.google/education/responsible-ai-practices" rel="nofollow">一套技术实践指南 Responsible AI Practices</a>，指导科学家和工程师们在构建人工智能产品的时候应该注意什么。<br/></p>
<p>一部分 Google 员工也在推特上表示对于这项原则的支持。Google 人工智能研究员 Dumitru Erhan 称看到这些原则非常开始，“是一个好的开始”。</p>
<p>但质疑的声音也同时出现了。</p>
<p>科技媒体 ZDNet <a href="https://www.zdnet.com/article/google-says-it-wont-build-ai-for-weapons/" rel="nofollow">在评论文章中指出</a>，即便 Google 说不让自己的技术用于武器开发，但一旦变成开源项目，这些技术和代码还是有可能被用于作恶。</p>
<p><a href="https://www.nytimes.com/2018/06/07/technology/google-artificial-intelligence-weapons.html" rel="nofollow">《纽约时报》则认为</a>，虽然不再续约 Maven 计划。但 Google 此前一再强调自己为国防部所做的工作并非出于“进攻目的”，听上去也符合目前这些指导原则。未来 Google 是否还会参加类似 Project Maven 的合同，目前尚不清楚。</p>
<p><br/></p>
<p>题图来自：电影《I, Robot》</p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>