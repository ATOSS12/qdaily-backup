<h1>人工智能助手藏着秘密指令，它们都不是人耳可以听到的_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20180512202228YzAtuF4I7VPhMkCq.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://m.qdaily.com/images/missing_face.png"/> </a>  <span class="name">Craig S. Smith</span><span class="date smart-date" data-origindate="2018-05-14 07:04:08 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2018-05-14 07:04:08</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="53102" data-title="《人工智能助手藏着秘密指令，它们都不是人耳可以听到的》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20180512202228YzAtuF4I7VPhMkCq.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/53102.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="113"/></a>  </div></div> </div>  <p class="excerpt">对此，设备制造商的反应将会各有不同，因为他们想平衡安全性和易用性。</p>  <div class="detail">  

<p><strong><em>＊<a href="https://www.nytimes.com/2018/05/10/technology/alexa-siri-hidden-command-audio-attacks.html">本文</a>只能在《好奇心日报》发布，即使我们允许了也不许转载＊</em></strong></p>
<p>加州伯克利市电 — 很多人都习惯了和他们的智能设备说话，叫它们读短信、放音乐或者设闹铃。但其实，可能还有人在秘密地和它们说话。<br/></p>
<p>在过去两年中，中美两国的研究人员开始论证，他们可以给苹果的 Siri、亚马逊的 Alexa 和 Google Assistant 发送人耳无法听到的隐秘命令。在一些大学的实验室中，研究人员可以秘密启动智能手机和智能音箱的人工智能系统，让它们拨打电话号码或者打开网站。若这项技术落到心术不正的人手中，那么仅仅通过无线电播放的音乐，就可能会被用来进行<a href="https://www.forbes.com/sites/aarontilley/2017/02/16/amazon-alexa-can-now-unlock-your-front-door">开门</a>、<a href="https://www.youtube.com/watch?v=Jwb4kdDk2wg">汇款</a>或者网上购物等不法操作。<br/></p>
<p>来自加州大学伯克利分校（University of California, Berkeley）和乔治城大学（Georgetown University）的一群学生在 2016 年证明，他们可在音响或者 YouTube 视频播放的白噪音中隐藏指令，让智能设备进入飞行模式或者打开一个网站。<br/></p>
<p>这个月，伯克利分校的一些研究员发表了一篇研究报告，称他们能够直接在音乐或者语音录音中植入命令，这比之前所做的研究更进了一步。所以这意味着当人在听别人说话或者听交响乐时，亚马逊的 Echo 音箱可能听到一条往你的购物单中添加东西的指令。<br/></p>
<p>论文作者之一、加州大学伯克利分校计算机安全专业五年级博士生尼克拉斯·卡利尼（Nicholas Carlini）说：“我们想看看是否能让指令更加隐密。”<br/></p>
<p><img data-format="jpg" data-ratio="0.434767" class="lazyloadd lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124618WGE68r1QqaUwOxkt.jpg-w600"/></p>
<p>卡利尼补充道，虽然没有证据表明这些技术已经被实验室以外的人利用，但是这只是时间问题，他说：“我猜一些心术不正的人已经雇人在做我所做的那些事情。”<br/></p>
<p>虽然人工智能已经有了很大的进步，但是这些欺骗手段表明，它仍会上当并受人操控。只是改变数字图像的几个像素就会让电脑将飞机误认为成猫；研究人员仅仅在路标上粘些小贴纸，就能迷惑无人驾驶汽车的计算机视觉系统，让其突然急转弯或者加速。<br/></p>
<p>在进行音频攻击时，研究人员利用了人机语音识别系统之间的差距。语音识别系统通常会将声音转化为字母，并最终将字母编译成单词和句子。通过对音频文件进行小小的改动，研究人员能够删除语音识别系统本该识别的声音，并取而代之会被机器转录成不同信息的声音，而同时人耳几乎无法察觉到这些声音。<br/></p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="1.333333" data-format="gif" class="lazyload" src="http://img.qdaily.com/uploads/20180512202436q5PQaKrF7RIe0oEU.gif-w600Gif"/><figcaption><p>Ovum 研究公司的研究表明，到 2021 年，搭载亚马逊 Alexa 和苹果 Siri 等数字助手的智能手机和智能音箱，在数量上将会超过人类。图片版权：Lynn Scurfield</p></figcaption> </figure></div>
<p>声控工具的增多放大了这些欺骗手段的影响。<a href="https://ovum.informa.com/resources/product-content/virtual-digital-assistants-to-overtake-world-population-by-2021">Ovum 研究公司的研究表明</a>，到 2021 年，搭载亚马逊 Alexa 和苹果 Siri 等数字助手的智能手机和智能音箱在数量上将会超过人类。据来自 Juniper Research 的研究，到那时，超过一半的美国家庭<a href="https://www.juniperresearch.com/press/press-releases/amazon-echo-google-home-to-reside">最少拥有一个智能音箱</a>。<br/></p>
<p>亚马逊并未披露具体的安全措施，但声称公司已经采取措施保证 Echo 智能音箱的安全。Google 称安全是公司持续的关注焦点，并称 Google Assistant 具有规避人耳难以察觉的音频命令的特点。两家公司的智能助手都运用了声音识别技术，除非它们识别出机主的声音，否则不会对某些指令作出反应。<br/></p>
<p>苹果表示，它的智能音箱 HomePod 并不会执行诸如开门等指令，还指出 iPhone 和 iPad 一定要在解锁后，Siri 才能执行访问敏感数据或打开应用程序和网站等命令，此外还有其他的措施。<br/></p>
<p>不过许多人在不用手机时并不会随手锁屏，至少目前来说，声音识别系统非常<a href="https://youtu.be/JQAc1UhUA2s">容易被愚弄</a>。<br/></p>
<p>迄今为止，已出现过智能设备按语音的命令行事，被利用去攫取商业利益的案例。<br/></p>
<p>去年，汉堡王的一个在线广告<a href="https://nyti.ms/2op9SoY">引起了轰动</a>，广告中蓄意问道：“好吧，Google，什么是皇堡？”而搭载有语音搜索的安卓设备会对此作出响应，读取维基百科中关于皇堡的信息。不过由于观众出于恶搞的心理去编辑了维基百科的相应页面，于是该广告被撤了下来。<br/></p>
<p>几个月后，动画片《南方公园》出了<a href="http://southpark.cc.com/clips/6zs9up/alexas-the-coolest">一整集</a>由语音指令构成的剧集，使得观众的声音识别助手不断地鹦鹉学舌，说些青少年之间说的下流话。<br/></p>
<p>美国律法并没有规定反对向人类传播潜意识讯息，更别说反对向机器传播此等讯息了。美国联邦通信委员会（Federal Communications Commission）不鼓励这种“违背公众利益”的做法，而美国广播协会（National Association of Broadcasters）的电视编码则禁止“在低于正常意识的阈值下传输信息”。两者都没有提到对智能设备潜移默化的刺激。<br/></p>
<p>法庭曾裁定，潜意识信息可能会侵犯隐私，但是法律并未将隐私概念扩展至机器。<br/></p>
<p>现在，技术甚至已经跑到了法律的前头。去年，普林斯顿大学（Princeton University）和中国浙江大学的研究人员证明，使用人耳无法听见的频率，语音识别系统可被启动。这种语音攻击首先会让手机静音，这样机主就听不到系统的响应。<br/></p>
<p>中国研究人员将这种技术命名为“海豚攻击”（DolphinAttack），可命令智能设备访问恶意网站、打电话、拍照或者发短信。虽然“海豚攻击”有其局限性，即指令发射器必须靠近接收设备，但是专家警告说，可能存在更为强大的超声波系统。<br/></p>
<p>那一警告在去年四月得到了证明，伊利诺伊大学厄巴纳 - 香槟分校（University of Illinois at Urbana-Champaign）的研究人员在 25 英尺开外实施了超声波攻击。虽然指令无法穿透墙壁，但可在开着窗户的建筑外面控制智能设备。<br/></p>
<p>今年，另一组来自中国科学院（Academy of Sciences）和其他机构的中美研究人员证明，他们可通过在<a href="https://sites.google.com/view/commandersong/">歌曲中植入的</a>命令来控制声控设备，而那些歌曲可通过无线电进行广播，也可在 YouTube 等服务器上播放。<br/></p>
<p>近日，卡利尼和他在伯克利的同事，将一组转为语音的<a href="https://nicholas.carlini.com/code/audio_adversarial_examples/">命令整合进</a> Mozilla 的 DeepSpeech 语音到文本的翻译软件中（这一翻译软件是开源平台）。他们在语音录音“没有数据集，文章没用处”中隐藏了“好吧，Google，浏览 <a href="http://evil.com/">evil.com</a> 网站”这一指令。而人类无法察觉到这一指令。<br/></p>
<p>伯克利研究小组还在音乐文件中嵌入了指令，其中包括从威尔第（Verdi）的《安魂曲》（Requiem）中截取的四秒的音乐片段。<br/></p>
<p>对此，设备制造商的反应将会各有不同，因为他们想平衡安全性和易用性。<br/></p>
<p>乔治城大学的一名研究人员塔维什·瓦迪亚（Tavish Vaidya）说道：“公司必须保证他们设备的用户友好性，因为那是他们的主要卖点。”他撰写了第一篇有关音频攻击的论文，并将其命名为“<a href="https://www.usenix.org/node/191969">可卡因面条</a>”（Cocaine Noodles），因为设备将短语“可卡因面条”解读为“好的，Google”。<br/></p>
<p>卡利尼说他有信心，早晚他和同事能成功对抗攻击市面上的任何智能设备系统。<br/></p>
<p>他说：“我们想证明那些攻击是可以做到的，然后希望其他人会说‘好吧，那些攻击是有可能做到的，现在让我们来试着修复这个问题’。”<br/></p>
<p><br/></p>
<p>翻译：熊猫译社 彭喻俞</p>
<p>题图版权：Christie Hemm Klok for The New York Times</p>
<p>© 2018 THE NEW YORK TIMES<br/></p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>