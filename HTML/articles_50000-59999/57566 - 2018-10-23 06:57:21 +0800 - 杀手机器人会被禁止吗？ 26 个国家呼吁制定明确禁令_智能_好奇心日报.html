<h1>杀手机器人会被禁止吗？ 26 个国家呼吁制定明确禁令_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20181022210417wjZOmHy5qVxFaD7k.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://m.qdaily.com/images/missing_face.png"/> </a>  <span class="name">Adam Satariano</span><span class="date smart-date" data-origindate="2018-10-23 06:57:21 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2018-10-23 06:57:21</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="57566" data-title="《杀手机器人会被禁止吗？ 26 个国家呼吁制定明确禁令》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20181022210417wjZOmHy5qVxFaD7k.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/57566.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="106"/></a>  </div></div> </div>  <p class="excerpt">尽管倡导组织一再要求推进针对人工智能武器的禁令，它短期内不太可能达成</p>  <div class="detail">  

<p nocleanhtml="true"><b><i>＊<a href="https://www.nytimes.com/2018/10/19/technology/artificial-intelligence-weapons.html" rel="nofollow">本文</a>只能在《好奇心日报》发布，即使我们允许了也不许转载＊</i></b></p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 29.2px; font: 14.0px 'PT Serif'; color: #17080a; -webkit-text-stroke: #17080a} p.p2 {margin: 0.0px 0.0px 24.0px 0.0px; text-align: justify; line-height: 20.0px; font: 10.0px 'PT Serif'; color: #17080a; -webkit-text-stroke: #17080a} p.p3 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 20.0px; font: 10.0px 'PT Serif'; color: #17080a; -webkit-text-stroke: #17080a} p.p4 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 20.0px; font: 10.0px 'PT Serif'; color: #17080a; -webkit-text-stroke: #17080a; min-height: 13.0px} p.p5 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 10.0px 'PT Serif'; color: #17080a; -webkit-text-stroke: #17080a} span.s1 {font-kerning: none} span.s2 {font-kerning: none; color: #c01900; -webkit-text-stroke: 0px #c01900} span.s3 {font: 10.0px 'PT Serif'; text-decoration: underline ; font-kerning: none; color: #0433ff; -webkit-text-stroke: 0px #0433ff} span.s4 {text-decoration: underline ; font-kerning: none; color: #0433ff; -webkit-text-stroke: 0px #0433ff} span.s5 {font-kerning: none; color: #000000; -webkit-text-stroke: 0px #000000} ]]></style>  </p>
<p>伦敦电 — 美国国防部正在开发一种自主式导弹，能使用软件自主选择目标。英国军方的一种人工智能无人机可以自己识别射击点。俄罗斯也展示过不需要士兵在里面作战的坦克。<br/></p>
<p>多年来，人工智能技术促使军方领导人思考一种几乎无需人类参与的未来战争。但随着作战能力的提高，自主武器投入战场越来越不再是个假想。<br/></p>
<p><a href="https://www.nytimes.com/2016/10/26/us/pentagon-artificial-intelligence-terminator.html?module=inline" style="background-color: rgb(255, 255, 255);" rel="nofollow">软件和算法可能做出生死攸关的决定</a>，这给一个名为“阻止杀手机器人运动”（Campaign To Stop Killer Robots）的组织增添了新的紧迫感。该组织召集了军备控制倡导者、人权组织和技术专家，敦促联合国起草一份全球条约，禁止在无人操控的情况下使用武器。就像在网络空间，网络攻击没有明确的交战规则一样，在使用自动化武器方面目前也还没有划定红线。<br/></p>
<p>一些外交官担心，如果没有防扩散协议，世界将陷入一场由算法驱动的军备竞赛。<br/></p>
<p><img data-format="jpg" data-ratio="0.431481" class="lazyloa lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124630Jo20tv7p63SFNTHe.jpg-w600"/></p>
<p>9 月 25 日，在纽约联合国大会开幕时的一次演讲中，联合国秘书长安东尼奥·古特雷斯（Antonio Guterres）将人工智能武器与气候变化、日益加剧的收入不平等一道列为了全球风险。<br/></p>
<p>古特雷斯说，“让我们如实地看待这个问题：机器拥有夺走人类生命的自由裁量权和权力，这种前景在道德上令人反感。”<br/></p>
<p>两周前，欧盟负责外交和安全政策的高级代表费德丽卡·莫盖里尼（Federica Mogherini）表示，这些武器“影响了我们全体人类的安全”，决定生死的权力必须掌握在人类手中。<br/></p>
<p>共有 26 个国家呼吁制定明确的禁令，要求在使用武力时必须施以某种形式的人为控制。但禁止人工智能武器的可能性很小。包括美国在内的几个有影响力的国家都不愿意在该技术仍处于发展阶段时对其加以限制。<br/></p>
<p>外交官们一直未能就如何实施或执行全球政策达成共识。一些人呼吁达成自愿协议，另一些人则希望制定具有法律约束力的规则。<br/></p>
<p>今年 8 月，联合国在日内瓦为此举行了一次会议，有 70 多个国家参加，但进展甚微。因为美国和其他国家表示，在全面限制人工智能武器之前，需要更好地了解这项技术。另一轮会谈预计将于今年晚些时候举行。<br/></p>
<p>一些人担心禁令会影响民用研究。在人工智能和机器学习领域，最前沿的工作大多来自各所大学和 Google、Facebook 等公司。但这些技术大多可以用于军事用途。<br/></p>
<p>“很多人工智能技术都是在政府之外开发出来并向公众发布的，”<a href="https://www.nytimes.com/2018/06/09/technology/elon-musk-mark-zuckerberg-artificial-intelligence.html?module=inline" style="background-color: rgb(255, 255, 255);" rel="nofollow">硅谷组织 OpenAI </a>的发言人杰克·克拉克（Jack Clark）说，该组织提倡更慎重地采用人工智能。“这些技术具有可应用于许多不同领域的通用能力，包括武器化。”<br/></p>
<p>在任何人工智能武器投入战场之前，主要的技术挑战仍然存在。欧洲研究所（Institute for European Studies）专门研究新兴军事和安全技术的研究员马艾克·维尔布鲁根（Maaike Verbruggen）说，人类和机器之间的交流沟通仍然有限，这使得人类很难理解人工智能机器如何做出决定。她表示，我们还需要制定更好的防护措施，以确保机器人的行动符合预期。<br/></p>
<p>不过，为伦敦的市场研究公司 Jane’s by IHS Markit 研究军事支出的分析师德里克·梅普（Derrick Maple）认为，未来 20 年，相关技术将取得重大进展。他说，随着技术变化，任何国际协议都可能是徒劳的；一旦发生战争，各国就会把协议撕成碎片。<br/></p>
<p>“你不能制定交战规则，”梅普尔说，“如果敌人要做什么，那么你也不得不做些什么。不管你制定了什么规则并落实到位，一旦发生冲突，这些规则都会被抛到九霄云外。”<br/></p>
<p>因为发现了一个新的收入来源，国防承包商们急于建造下一代的机器。去年，波音重组了其国防业务，其中一个部门的工作重心便是无人机和其他无人武器。该公司还收购了自主飞行器制造商 Aurora Flight Sciences。洛克希德·马丁公司（Lockheed Martin）、BAE系统公司和雷神公司（Raytheon）等其他国防承包商也在进行类似的调整。<br/></p>
<p>在该领域工作了 40 多年的梅普尔估计，未来 10 年，无人机和舰船等无人驾驶军用车辆的军费支出将超过 1200 亿美元。<br/></p>
<p>目前尚未发现有国家在战场上部署完全自主的武器，但军方多年来一直在使用自动化技术。以色列的“铁穹”（Iron Dome）防空系统可自动探测并摧毁来犯的火箭弹。韩国使用自主设备探测朝鲜边境的动向。<br/></p>
<p>梅普尔希望在将责任完全移交给机器人之前，人类和机器之间能有更多的合作。例如，研究人员正在研究如何用人工智能无人机舰队来支援飞机和坦克。<br/></p>
<p>2016 年，五角大楼在莫哈韦沙漠（Mojave Desert）的一次测试中强调了它的能力。100 多架无人机被从一架战斗机上胡乱扔下，之后它们迅速聚集，冲向并包围目标。从五角大楼分享的雷达视频来看，这些无人机看起来就像一群迁徙的椋鸟。<br/></p>
<p>当这些无人机在头顶上空飞行时，没有人在驾驶它们，而且这些机器看上去与任何人都能从消费电子产品商店买到的机器没有太大区别。按照设定的程序，这些无人机可以相互独立地进行沟通，集体行动、达到目标。<br/></p>
<p>五角大楼战略能力办公室主任威廉·罗珀（William Roper）当时表示：“它们是一个集体有机体，共享一个分布式大脑进行决策，并能像自然界中的动物群体一样相互适应。”<br/></p>
<p>对于那些为自主武器发展深感担忧的人来说，其含意是显而易见的。<br/></p>
<p>“你是在把杀人的决定交给一台机器，”奥地利政府裁军部门的负责人托马斯·哈吉诺奇（Thomas Hajnoczi）说，“但机器没有任何道德评判准则，而且毫无怜悯之心。”<br/></p>
<p><br/></p>
<p>翻译：熊猫译社 刘溜</p>
<p>题图来自 <a href="https://unsplash.com/photos/oMqswmrie4Y" rel="nofollow">Martin Sanchez on Unsplash</a><br/></p>
<p>© 2018 THE NEW YORK TIMES</p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>