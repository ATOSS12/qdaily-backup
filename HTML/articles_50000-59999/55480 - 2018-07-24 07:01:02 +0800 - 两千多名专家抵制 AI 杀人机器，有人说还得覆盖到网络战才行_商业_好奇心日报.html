<h1>两千多名专家抵制 AI 杀人机器，有人说还得覆盖到网络战才行_商业_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20180722173805gA42NTRCGOFMwBua.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://img.qdaily.com/user/face/20160702200213C9AwiraDF6c5vPTz.jpg?imageMogr2/auto-orient/thumbnail/!80x80r/gravity/Center/crop/80x80/ignore-error/1"/> </a>  <span class="name">宣海伦</span><span class="date smart-date" data-origindate="2018-07-24 07:01:02 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2018-07-24 07:01:02</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="55480" data-title="《两千多名专家抵制 AI 杀人机器，有人说还得覆盖到网络战才行》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20180722173805gA42NTRCGOFMwBua.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/55480.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="57"/></a>  </div></div> </div>  <p class="excerpt">这项协议的初衷是“希望用道德和舆论令军火商蒙羞”。</p>  <div class="detail">  

<p nocleanhtml="true"><a href="https://futureoflife.org/lethal-autonomous-weapons-pledge/?cn-reloaded=1" rel="nofollow">200 个组织和 2639 名 AI 研究人员和专家签署了一份承诺</a>，表示永远不会参与开发或制造在自主状态下具备识别和攻击行为的人工智能机器人。<br/></p>
<p>包括埃隆·马斯克、Deep Mind 联合创始人 Mustafa Suleyman 和 Google Brain 创立者、今年四月刚接手 Google AI 部门的 JeffDean 都签署了这项承诺。</p>
<p class="">这听起来是件不错的事情，<a href="http://www.businessinsider.com/elon-musk-pledge-not-to-build-killer-ai-misses-the-point-2018-7" rel="nofollow">不过牛津互联网研究所的 Mariarosaria Taddeo 博士认为这份承诺书只提及了机器人 AI</a>，没有提及应用于网络安全的软件 AI，后者在目前国际冲突背景下使用更频繁。</p>
<p class="">美国军方将这两种分别区分为运动中的 AI（即应用于机器人的 AI）和静止的 AI（可在软件程序中找到）。后者相对更少吸引公众的关注，Taddeo 博士担心 AI 防御系统的投入会严重升级网络战的性质。</p>
<p class="">在网络安全应用上，AI 可以保护所部署的系统，也能自主瞄准并响应来自另一台机器的攻击。如果是国家或洲际间的网络冲突，这看似不会造成物理伤亡，但很可能会严重损害国家基础设施，比如导致全国停电，或者篡改空中控制系统。</p>
<p class="">“如果我们开始使用自主防御并自主攻击的人工智能系统，那么很容易陷入无法控制并不断升级的动态破坏中。” <a href="http://www.businessinsider.com/elon-musk-pledge-not-to-build-killer-ai-misses-the-point-2018-7" rel="nofollow">Taddeo 表示</a>。</p>
<p class="">以上这些信息，包括签署抵制 AI 杀手的那份协议在内，虽然听起来略科幻，但这条消息背后传递的信息是：让机器来决定人类的生存和死亡，不再是个遥远的话题。并且就目前而言，似乎除了用道德和舆论施压，目前并没有政府出台法律和规范有效控制杀手机器人的发展。</p>
<p><img data-format="jpg" data-ratio="0.413221" class="lazylod lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124612v5wnh60OmgCAUPGJ.jpg-w600"/></p>
<p>军方一直是人工智能技术的最大资助者和使用者之一。<a href="https://www.theguardian.com/science/2018/jul/18/thousands-of-scientists-pledge-not-to-help-build-killer-ai-robots" rel="nofollow">英国国防部计划用 20 亿英镑购买一架全新的英国皇家空军战斗机“暴风雨”（Tempest）</a>，据说这架战机可以在没有飞行员的情况下飞行。但英国军方表示，英国还没有发展出致命的自主武器系统，并承诺会对其部署的武器进行监督和控制。<br/></p>
<p>去年 8 月，<a href="https://www.dropbox.com/s/g4ijcaqq6ivq19d/2017%20Open%20Letter%20to%20the%20United%20Nations%20Convention%20on%20Certain%20Conventional%20Weapons.pdf?dl=0" rel="nofollow">埃隆·马斯克等 100 多位科技公司创始人就签署过一份公开信</a>，呼吁联合国禁止开发和使用人工智能武器。</p>
<p>研究人员担心，以人工智能的发展速度来看，制造出未经人类控制者同意即可以识别、跟踪和射击人类目标的 AI 机器并非天方夜谭。而这意味着让机器掌握着人类的生杀大权。</p>
<p><a href="https://www.cnbc.com/2017/09/04/elon-musk-says-global-race-for-ai-will-be-most-likely-cause-of-ww3.html" rel="nofollow">马斯克曾在推特表露担忧</a>：全球人工智能军备竞赛将引发第三次世界大战。已故的著名物理学家<a href="https://www.cnbc.com/2017/11/06/stephen-hawking-ai-could-be-worst-event-in-civilization.html" rel="nofollow">史蒂芬·霍金也在去年 11 月表示</a>，“除非我们学会如何准备和避免潜在的风险，否则人工智能可能是我们文明史上最严重的事件。”<br/></p>
<p>本月发起这一承诺书的组织是波士顿的生命未来研究所（Future of Life Institute），希望能够以此呼吁各国政府商定相关规范、法律。</p>
<p><a href="https://www.theguardian.com/science/2018/jul/18/thousands-of-scientists-pledge-not-to-help-build-killer-ai-robots" rel="nofollow">来自蒙特利尔学习算法研究所的 Yoshua Bengio 认为</a>，如果这一承诺能够让那些制造自主武器的公司和军事组织蒙羞，公众舆论就会反对他们。“（比方说）尽管美国没有签署禁止地雷的条约，但由于国际条约和舆论谴责，美国公司已经停止制造地雷。”<br/></p>
<p>尽管在这份长长的签名书上，还有类似于 Skype 这样让人很难与 AI 杀人机器联系在一起的公司，<a href="https://www.theverge.com/2018/6/1/17418406/google-maven-drone-imagery-ai-contract-expire" rel="nofollow">但就好像 Google 的 Project Maven 项目一样</a>，看似无害的云服务也可以被用于实时军事监控。</p>
<p><a href="https://www.theguardian.com/science/2018/jul/18/thousands-of-scientists-pledge-not-to-help-build-killer-ai-robots" rel="nofollow">英国兰卡斯特大学教授 Lucy Suchman 表示</a>，“首先我承诺会追踪我的技术的后续使用，并公开反对他们的应用程序来实现自动化目标识别；其次我会拒绝参与任何建议或直接帮助将这项技术整合到自主武器系统中。”<br/></p>
<p>实际情况是，研究人员虽然可以不主动研究自主武器，但很难避免其他人不当使用他们公开发表的突破性研究成果。</p>
<p><br/></p>
<p>题图来源：《机械姬》</p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>