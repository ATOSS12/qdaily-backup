<h1>撞向小宝宝还是老太太的道德选择课题， MIT 发现了影响因素_文化_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20181031144200yg5VFaMCD2zcbni0.gif?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://img.qdaily.com/user/face/20190519025649FGyKLQ8AYZJwMR6U.jpg?imageMogr2/auto-orient/thumbnail/!80x80r/gravity/Center/crop/80x80/ignore-error/1"/> </a>  <span class="name">张依依</span><span class="date smart-date" data-origindate="2018-11-04 07:22:01 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2018-11-04 07:22:01</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="57851" data-title="《撞向小宝宝还是老太太的道德选择课题， MIT 发现了影响因素》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20181031144200yg5VFaMCD2zcbni0.gif?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/57851.html?source=feed&amp;utm_medium=website" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="472"/></a>  </div></div> </div>  <p class="excerpt">这辆自动驾驶的汽车该如何选择？</p>  <div class="detail">  

<p finallycleanhtml="true" nocleanhtml="true">晴朗的一天，你正站在一条铁轨旁，突然一辆列车从前方失控驶来。此时铁轨上站着 5 名施工的工人，列车的速度很快，他们已经来不及闪躲。你手边刚好有一个可以切换列车行驶轨道的手柄，但另一道铁轨上也站着一个戴耳机的人，没有留意到列车。</p>
<p>是否要拉动手柄，牺牲一个人来挽救 5 个人的生命？这是经典的“有轨电车难题”（又称电车问题），由哲学家 Philippa Foot 于 1967 年提出， 1985 年，美国道德哲学家 Judith Jarvis Thomson 又改编出了另几种情境变化。</p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="1.000000" data-format="png" class="lazyload" src="http://img.qdaily.com/uploads/20181031142702bpY3oTBDCMuivma7.png-w600"/><figcaption><p>“有轨电车难题”图示。来源于<a href="https://commons.wikimedia.org/wiki/Category:Trolley_problem#/media/File:Trolley_problem.svg" rel="nofollow">Wiki Commons</a></p></figcaption> </figure></div>
<p>电车问题的存在不在于解决问题，而旨在通过一个两难的“道德困境”，让人对生活中的决策，和决策过程产生进一步的思考。提出后的几十年里，已经激发了全世界范围内的热切讨论，在流行文化的创作中也频频重现。但随着自动驾驶技术愈发接近实现和普及，近年来对于电车问题的讨论，不论是热度还是紧迫性，都已然上升到另一个层面。</p>
<p>2014 年，麻省理工学院（ MIT ）媒体实验室设计了一个名为<a href="http://moralmachine.mit.edu/" rel="nofollow">道德机器</a>的实验。他们创建了一个简易的游戏平台，收集人们在电车问题的不同变化中会做出什么样的决策。而站在决策者，也就是实验的参与玩家的第一视角，会被提出这样的问题：这辆自动驾驶的汽车该如何选择？</p>
<p>道德机器假设的情境测试了 9 种不同比较下人们的选择分化：</p>
<p>选择人类还是宠物？乘客还是行人？人多的还是人少的？男人还是女人？小孩子还是老人？健康的还是肥胖的？社会地位高的还是社会地位底的？遵守交规的还是乱闯红灯的？以及作为这辆车，应该正常行驶不作为，还是做出选择？</p>
<p><img data-format="jpg" data-ratio="0.408706" class="lazyloadd lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124606JSpdaCk3eAlgqD5x.jpg-w600"/></p>
<div class="com-insert-images multiple">
<figure style="margin: 0px;"> <img data-ratio="0.747384" data-format="png" class="lazyload" src="http://img.qdaily.com/uploads/20181031142937t9nc1452IFaELdrP.png-w600"/><figcaption>道德机器中的几种情境：撞向4名儿童还是5名老人？来源于<a href="http://moralmachine.mit.edu/" rel="nofollow">道德机器实验平台</a></figcaption> </figure><figure style="margin: 0px;"> <img data-ratio="0.694635" data-format="png" class="lazyload" src="http://img.qdaily.com/uploads/20181031142947fNrVtsGWMna6oX5x.png-w600"/><figcaption>道德机器中的几种情境：撞向一位医生还是一名流浪汉？来源于<a href="http://moralmachine.mit.edu/" rel="nofollow">道德机器实验平台</a></figcaption> </figure><figure style="margin: 0px;"> <img data-ratio="0.720863" data-format="png" class="lazyload" src="http://img.qdaily.com/uploads/20181031142956QAPdzTsX972lp8cW.png-w600"/><figcaption>道德机器中的几种情境：撞向护栏还是为了全车人的生命撞向行人？来源于<a href="http://moralmachine.mit.edu/" rel="nofollow">道德机器实验平台</a></figcaption> </figure>
</div>
<p>根据 <a href="https://www.technologyreview.com/s/612341/a-global-ethics-study-aims-to-help-ai-solve-the-self-driving-trolley-problem/?utm_campaign=social_button&amp;utm_source=twitter&amp;utm_medium=social&amp;utm_content=2018-10-25&amp;fbclid=IwAR1WLAaa19vhDVs9YM20mkmv-sK-JxgGrOWU0YS0TSXH5BHl0jRN1EBarIQ" rel="nofollow">MIT Tech Review</a> ，平台上线后，收到的反馈数远远超出研究人员的预料。四年内，来自 233 个国家和地区的数百万参与者，已经做出了 4000 万份决策回馈，使其成为有史以来全球针对道德偏好的最大规模研究之一。</p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="1.656410" data-format="png" class="lazyload" src="http://img.qdaily.com/uploads/20181031142814uQJkAW0IHXB4NmsV.png-w600"/><figcaption>世界地图上标出了实验参与者的地域分布。来源<a href="https://www.nature.com/articles/s41586-018-0637-6.epdf?referrer_access_token=uQpOsq480M7FDBBeT3_giNRgN0jAjWel9jnR3ZoTv0OR8PKa5Kws8ZzsJ9c7-2Qp8nbIwouAM66OQiCFCUYXQRFBcD903wux5GWjYtW-Qg0VsMn3IwcqIheAW9orF7HAHTuj2dGO9w6_6FqjM0JGEzqxeISMxLQ6LRIiQHcu8fV1gvDg6iRBbbuLNSjraQVARRN4K-lrJ0D-t4L3kk5gadlkepjvOsXJVXpJGmTejmTWDzUOkG2NoKNMYBUUCR1E8AgEG7BO-65rF2LkmGxDWRRxiOWH3D14WrmFPaEVckvNudAM8cCuVk2hKY8IUqQL0kbx5QO4Y_Upoq_BmxMFD4dF1Pepw8NgQe2iBjX_oz5vMIdXDwofVVSeUtNTgLqtRtoP67rmoUby0_h64FlXi3CNlgZmcIBWGR8gkTFm-tWPhI1WQpKu6i7_hMrBB8_t09Dw_LcOJ0YHE6P2_zZXjSC2_mNJSvxCIiYMN_doB2fv08igG1kDGUw3jnSHsO63BL17i2qWw-2kdHe1GM_idhsBaC_tb8IronqnHe86VCA%3D&amp;tracking_referrer=www.technologyreview.com" rel="nofollow">《自然》</a></figcaption> <div><div><div> </div></div></div></figure></div>
<p>近日，一篇发表在《自然》上的<a href="https://www.nature.com/articles/s41586-018-0637-6.epdf?referrer_access_token=uQpOsq480M7FDBBeT3_giNRgN0jAjWel9jnR3ZoTv0OR8PKa5Kws8ZzsJ9c7-2Qp8nbIwouAM66OQiCFCUYXQRFBcD903wux5GWjYtW-Qg0VsMn3IwcqIheAW9orF7HAHTuj2dGO9w6_6FqjM0JGEzqxeISMxLQ6LRIiQHcu8fV1gvDg6iRBbbuLNSjraQVARRN4K-lrJ0D-t4L3kk5gadlkepjvOsXJVXpJGmTejmTWDzUOkG2NoKNMYBUUCR1E8AgEG7BO-65rF2LkmGxDWRRxiOWH3D14WrmFPaEVckvNudAM8cCuVk2hKY8IUqQL0kbx5QO4Y_Upoq_BmxMFD4dF1Pepw8NgQe2iBjX_oz5vMIdXDwofVVSeUtNTgLqtRtoP67rmoUby0_h64FlXi3CNlgZmcIBWGR8gkTFm-tWPhI1WQpKu6i7_hMrBB8_t09Dw_LcOJ0YHE6P2_zZXjSC2_mNJSvxCIiYMN_doB2fv08igG1kDGUw3jnSHsO63BL17i2qWw-2kdHe1GM_idhsBaC_tb8IronqnHe86VCA%3D&amp;tracking_referrer=www.technologyreview.com" rel="nofollow">新论文</a>介绍了对于这批数据的分析。</p>
<p>一部分结果和人们的预期相差不大。比如总体来说，在相同的情况下，人们的反馈显示他们会选择挽救更多的生命，挽救儿童而不是成年人，挽救人类而不是宠物。</p>
<p>另一部分则显示出人们的决策趋向在地理、种族和社会经济地位方面的差异性。</p>
<p>比如说，虽然整体而言，人们的选择更加偏向于年轻人而不是老年人，但在一些东亚和中东国家，例如中国、日本和沙特阿拉伯，这种偏向的幅度不那么明显。研究人员猜测这与这些国家尊重长者的道德传统，以及集体主义文化背景有关。</p>
<p>另一个观察显示，国家繁荣（以 GDP 划分）和法治程度越低的地方，人们对于违法者，也就是闯红灯的行人越宽容，“大概是因为在他们的经验体系中，违法的后果和惩罚都相应地更弱。”</p>
<p>研究人员还发现，不是所有的情境下，人们都优先从数量上考虑应该挽救哪一边。而在这方面，来自个人主义文化背景，比如说美国和英国的参与者，则更加倾向于数量的重要性而不是其他因素。研究者猜测，这源于这些文化中对于个人生命价值的重视。</p>
<p>论文还阐述了一些有趣发现。比如国家贫富差距越大，人们在道德机器中对于富人和穷人的态度也更加不平等；人们整体上更倾向于女性而不是男性，在女性健康和寿命预期越长的地区，这种趋向更加明显；而且显然，比起猫，人们更加倾向于狗。</p>
<div class="com-insert-images"><figure style="margin: 0px;"> <img data-ratio="0.362039" data-format="png" class="lazyload" src="http://img.qdaily.com/uploads/20181031143132rkT0CjZhdzxwiaPg.png-w600"/><figcaption><p>a图蓝色柱状图显示出对于右侧群体的倾向程度。b图显示了对于单个群体整体的倾向程度。来源于<a href="https://www.nature.com/articles/s41586-018-0637-6.epdf?referrer_access_token=uQpOsq480M7FDBBeT3_giNRgN0jAjWel9jnR3ZoTv0OR8PKa5Kws8ZzsJ9c7-2Qp8nbIwouAM66OQiCFCUYXQRFBcD903wux5GWjYtW-Qg0VsMn3IwcqIheAW9orF7HAHTuj2dGO9w6_6FqjM0JGEzqxeISMxLQ6LRIiQHcu8fV1gvDg6iRBbbuLNSjraQVARRN4K-lrJ0D-t4L3kk5gadlkepjvOsXJVXpJGmTejmTWDzUOkG2NoKNMYBUUCR1E8AgEG7BO-65rF2LkmGxDWRRxiOWH3D14WrmFPaEVckvNudAM8cCuVk2hKY8IUqQL0kbx5QO4Y_Upoq_BmxMFD4dF1Pepw8NgQe2iBjX_oz5vMIdXDwofVVSeUtNTgLqtRtoP67rmoUby0_h64FlXi3CNlgZmcIBWGR8gkTFm-tWPhI1WQpKu6i7_hMrBB8_t09Dw_LcOJ0YHE6P2_zZXjSC2_mNJSvxCIiYMN_doB2fv08igG1kDGUw3jnSHsO63BL17i2qWw-2kdHe1GM_idhsBaC_tb8IronqnHe86VCA%3D&amp;tracking_referrer=www.technologyreview.com" rel="nofollow">《自然》</a></p></figcaption> <div><div><div> </div></div></div></figure></div>
<p>“人类历史上从没有像现在一样，允许机器在没有实时控制的情况下在片刻间就决定人们的生死。”论文的结尾写道。在同样的情况下，人类驾驶员只有瞬间做出决策，不论结果如何，外界也许都不会对其大加指责。但自动驾驶却允许将道德标准事先进行编程，也可以说，科技的进步为人类带来了从未有过的伦理挑战。</p>
<p>但论文也承认这些结果并不是对不同国家人群选择的明确评估，也并不试图对政策决策者做出建议。</p>
<p>“我们试图在这里展示的是描述性伦理：人们对道德决策的偏好。”该论文的共同作者 Edmond Awad 告诉 <a href="https://www.theverge.com/2018/10/24/18013392/self-driving-car-ethics-dilemma-mit-study-moral-machine-results" rel="nofollow">The Verge</a> 。“当涉及到规范伦理学，就是在现实世界中的设计应该留给专家。”</p>
<p>线上测试入口： <a href="http://moralmachine.mit.edu/" rel="nofollow">http://moralmachine.mit.edu/ </a>；题图来源于 <a href="https://giphy.com/gifs/natgeochannel-car-origins-dqQxplKANtn8c" rel="nofollow">Giphy</a></p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>