<h1>人工智能产品越来越多，但当中有些是找人类假扮的_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20180709175413ir1ETWpqe2xgVhlv.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://img.qdaily.com/user/face/20180403082211d5EYRce6aS2plAyz.jpg?imageMogr2/auto-orient/thumbnail/!80x80r/gravity/Center/crop/80x80/ignore-error/1"/> </a>  <span class="name">王毓婵</span><span class="date smart-date" data-origindate="2018-07-09 18:54:55 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2018-07-09 18:54:55</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="55048" data-title="《人工智能产品越来越多，但当中有些是找人类假扮的》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20180709175413ir1ETWpqe2xgVhlv.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/55048.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="119"/></a>  </div></div> </div>  <p class="excerpt">如何创办一家 AI 公司？1.  雇一群低薪人类假扮想要假扮人类的机器人；2.  等待 AI 被开发出来。</p>  <div class="detail">  

<p class="" nocleanhtml="true"><a href="https://www.theguardian.com/technology/2018/jul/06/artificial-intelligence-ai-humans-bots-tech-companies" rel="nofollow">《卫报》</a>引用 ReadMe CEO Gregory Koberger 的说法称，有不少科技公司会用人类来假扮机器人，因为开发一个人工智能的项目太难了，相比之下反而用人类来做这些事会更容易。</p>
<p class="">“使用人来完成一些工作可以让你跳过大量的技术开发环节。虽然人类不能像人工智能那样形成规模化生产，但他们可以帮助你在早期跳过最困难的部分。”Gregory Koberger 说，这种情况并不少见，他自己都见过不少“假 AI”了。</p>
<p class="">以本月初的 Google 邮件泄露丑闻为例，《华尔街日报》称，为了优化自己的服务体验，一些基于 Gmail 的第三方邮件 App 允许自己的员工阅读用户的邮件。除了侵犯用户隐私的问题外，这里面还有另外一个问题——为什么阅读邮件的是人类而不是人工智能？</p>
<p class="">涉事公司之一，eDataSource 的前任 CTO Thede Loder <a href="https://www.wsj.com/articles/techs-dirty-secret-the-app-developers-sifting-through-your-gmail-1530544442" rel="nofollow">表示</a>，让员工阅读用户电子邮件已成为此类数据公司的“常见操作”。但是他解释说，这么做是为了改进软件算法，训练人工智能系统，所以工程师们只是“偶尔查看用户的电子邮件”。</p>
<p class="">存在类似做法的公司还有 Return Path 和 Edison Software 等，他们的解释与 eDataSource 相近，即人类阅读信息只是为了训练和改进人工智能，他们并不把这种做法看作“假扮人工智能”，但是没有任何一家公司的隐私政策中有提到会有人类查看用户的电子邮件。</p>
<p class="">类似的公司还有投入了巨额科研资金的 Facebook，他们<a href="https://www.recode.net/2015/11/3/11620286/facebooks-virtual-assistant-m-is-super-smart-its-also-probably-a-human" rel="nofollow">曾表示</a>需要人类来辅助他们的人工智能助手，形成了一个人工智能辅助用户，工程师辅助人工智能的怪圈——当然这只是在早期，他们的机器人学会深度学习之前。</p>
<p class="">而且显然并不是所有人类都只是在“辅助人工智能”，有一些确实是“做了本该由人工智能来做的工作”。</p>
<p><img data-format="jpg" data-ratio="0.445956" class="lazyloadd lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124606JSpdaCk3eAlgqD5x.jpg-w600"/></p>
<p>2008 年，一家致力于将语音邮件转换为短信的公司<a href="https://www.theguardian.com/business/2009/jul/23/spinvox-answer-back" rel="nofollow"> Spinvox</a>，被指控利用人工而非机器来完成工作。2016 年，<a href="https://www.bloomberg.com/news/articles/2016-04-18/the-humans-hiding-behind-the-chatbots" rel="nofollow">彭博社报道</a>称，创业公司 X.ai 推出的“人工智能个人助理” Amy 可以帮助用户完成安排会议和发送电子邮件等简单任务，但其实 Amy 的背后真的有一支不眠不休的人工团队。类似的公司还有推出了聊天机器人的 Clara 等。</p>
<p>受访员工表示，自己需要每天工作 12 个小时，假扮机器人来做一些单调乏味的工作。</p>
<p>2017 年，推出了商业费用管理 App 的公司 Expensify 承认，它一直使用人工来处理一部分它对外声称用“智能扫描技术”（smartscan technology）来完成的收据转录工作。事实上他们是将用户上传的收据扫描，然后把照片被发布到亚马逊的 Mechanical Turk 众包劳动工具上，最后由上面的低薪工作者们手动浏览和抄录完成。</p>
<p class="">科技公司为什么要这样做？当然首先是为了装作行业翘楚以博得关注度和投资。“这是他们不会告诉投资者的小秘密。”《卫报》称。</p>
<p class="">Readmeio 创始人 Gregory Koberger 曾经发 Twitter 开过一个小玩笑：如何创办一家 AI 公司？1.雇一群低薪人类假扮想要假扮人类的机器人；2.等待 AI 被开发出来。</p>
<p class="">除了这种比较功利的动机外，还有一种原因，是心理学家发现当用户以为自己面对的是一台机器人时，会更容易放下戒备。当涉及敏感话题时，这种性状表现得更加明显。</p>
<p class="">来自南加州大学的一个团队用一位名叫艾莉（Ellie）的虚拟心理治疗师进行了<a href="https://www.wired.com/story/virtual-therapists-help-veterans-open-up-about-ptsd/" rel="nofollow">测试</a>。他们发现，当退伍军人知道艾莉是一个人工智能系统而不是有人在背后操纵机器时，他们更容易表露自己的症状。<br/></p>
<p class="">这种情形不仅仅存在于医疗问诊中，它几乎体现在人机关系的方方面面。比如说，当被告知读取你邮件内容的只是机器人时，人们的抵触情绪明显会比得知工程师偷窥自己邮件时轻得多。和小冰等聊天机器人聊天时，人们也更容易说出平常不太能说出口的话。</p>
<p class="">“但是这就是欺骗。不欺骗别人应该是一个道德准则。”心理学家、Woebot（一种专注于心理健康辅导的聊天机器人）创始人艾莉森·达西（Alison Darcy）说。“这简直是巫师般的操作。”</p>
<p class=""><br/></p>
<p class="">题图/蔡明在 1996 年春节联欢晚会上饰演机器人</p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>