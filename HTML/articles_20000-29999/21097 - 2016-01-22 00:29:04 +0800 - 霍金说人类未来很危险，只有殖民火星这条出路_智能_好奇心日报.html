<h1>霍金说人类未来很危险，只有殖民火星这条出路_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/20160607183937gycsVEZ0TnHSRUKF.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://m.qdaily.com/images/missing_face.png"/> </a>  <span class="name">王震宇</span><span class="date smart-date" data-origindate="2016-01-22 00:29:04 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2016-01-22 00:29:04</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="21097" data-title="《霍金说人类未来很危险，只有殖民火星这条出路》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20160607183937gycsVEZ0TnHSRUKF.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/21097.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="117"/></a>  </div></div> </div>  <p class="excerpt">霍金又提世界末日了，真不“正能量”。</p>  <div class="detail">  

<p>&#13;
	你会相信，人类离灭亡最近的时刻，是下一个百年吗？信不信由你，至少霍金信了。&#13;
</p>&#13;
<p>&#13;
	<a href="http://www.bbc.com/news/science-environment-35344664" target="_blank">在 BBC 近期的采访中</a>，<span style="text-align:left;">史蒂芬·</span>霍金警告道：由于科学和技术的快速发展，在未来的一百年里，人类将时刻处在自我毁灭的危险之中。&#13;
</p>&#13;
<p>&#13;
	作为著名物理学家霍金认为，迅猛发展的科技在为我们带来各种福利的同时，也创造了“新的出问题的方式”，这带来的高风险是人类很难控制的。他尤其强调核战争、全球气候变暖和基因工程病毒的危险性，表示这三者很可能就是我们自创末日的预兆。&#13;
</p>&#13;
<p>&#13;
	这并非是霍金第一次提到世界末日。早在 2014 年，霍金就曾提醒我们注意人工智能的威胁。他认为一旦人工智能跨过了与人类智慧相同的“奇点”（ Singular Point ），我们可能会面临“智慧爆炸”（intelligence explosion），届时，人工智能在智慧上超越我们，而且将比人类超过蜗牛的程度还大。这对人类产生的影响，要么就是最好的，要么就是最糟糕的。它既可能让人类永生，也可能让人类毁灭。&#13;
</p>&#13;
<p>&#13;
	不过，霍金还在采访中表示，他是一个彻底的乐观主义者。他相信人类终有办法克服面临的问题。对此霍金给出的建议是：殖民火星。他觉得这个方法可以保证在最坏的情况降临时，还能有一部分人类在其他星球的“避风港”中继续生存下去。&#13;
</p>&#13;
<p>&#13;
	但是，在接下来的一个世纪，这恐怕很难成为现实。而霍金认为，尽管现在发生全球性灾难的几率很低，但它会随着时间的推移增加，并在接下来的一千年到一万年之间变成 100%。而人类正在没有安全网的情况下飞速地前进着，这让下个世纪变成了“最危险的 100年”。所以霍金说：“未来的 100 年生死攸关，所以我们必须非常小心。”&#13;
</p>&#13;
<p>&#13;
	 &#13;
</p>&#13;
<p>&#13;
	<strong>题图来自：</strong>Flickr@<a href="http://www.flickr.com/photos/lwpkommunikacio/">Lwp Kommunikáció</a> &#13;
</p>&#13;
<div>&#13;
</div>&#13;
<p>&#13;
</p>



 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>