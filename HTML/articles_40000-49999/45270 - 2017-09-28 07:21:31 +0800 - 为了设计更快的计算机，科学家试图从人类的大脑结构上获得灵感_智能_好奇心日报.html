<h1>为了设计更快的计算机，科学家试图从人类的大脑结构上获得灵感_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/article/article_show/201709181031416CyZdo2tbV3klHSE.jpg?imageMogr2/auto-orient/thumbnail/!755x450r/gravity/Center/crop/755x450/ignore-error/1"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://m.qdaily.com/images/missing_face.png"/> </a>  <span class="name">Cade Metz</span><span class="date smart-date" data-origindate="2017-09-28 07:21:31 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2017-09-28 07:21:31</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="45270" data-title="《为了设计更快的计算机，科学家试图从人类的大脑结构上获得灵感》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/201709181031416CyZdo2tbV3klHSE.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/45270.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="143"/></a>  </div></div> </div>  <p class="excerpt">新的科技正在测试计算机半导体能力的界限，为了弄清楚这个问题，研究人员正在从大自然中寻找灵感。</p>  <div class="detail">  

<p nocleanhtml="true"><strong><em>＊</em><em><a href="https://www.nytimes.com/2017/09/16/technology/chips-off-the-old-block-computers-are-taking-design-cues-from-human-brains.html?mcubz=3" rel="nofollow">本文</a></em><em>只能在《好奇心日报》发布，即使我们允许了也不许转载＊ </em></strong><br/></p>
<p>旧金山电 – 如今人们对计算机有着很高的期待，它们应该能和我们对话、认识从人脸到花朵的各种东西，可能不久之后还要学会开车。所有这些人工智能都需要大量运算能力，甚至把最先进的计算机的算力都用到了极致。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} ]]></style>  </p>
<p>为了应对不断增长的算力需求，一些科技巨头已经开始从生物学领域寻找线索。它们正在重新思考计算机的本质，打造更像人类大脑的计算机，利用一个中枢脑干管理神经系统，把听觉和视觉等特定任务分配给周围的大脑皮质。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} ]]></style>  </p>
<p>停滞多年后，计算机又开始进化了，整个平台将默默地过渡到全新的的架构上，带来广泛而持久的影响。它将为依靠人工智能系统完成的各种工作提速，从而实现我们让计算机在现实世界里自主行动的梦想。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p><img data-format="jpg" data-ratio="0.385876" class="lazylad lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124623tvJN5Uq9dWRZ60jS.jpg-w600"/></p>
<p>长期以来，英特尔都是芯片设计和制造行业的巨头，而此次技术进化有可能会削弱它的实力，并最终重塑年产值达 3350 亿美元的半导体行业——从把互联网送到你 iPhone 上的数据中心，到未来的虚拟现实头戴设备和无人机，它们的核心都是半导体。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 12.5px Georgia; font-kerning: none; color: #262626; -webkit-text-stroke: 0px #262626} span.s3 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>约翰·亨尼斯（John Hennessy）曾担任斯坦福大学董事会主席，1990 年代中期撰写了计算机设计方面的一本权威著作，现在他是 Google 的母公司 Alphabet 的一名董事。他说：“这是一次剧变，现有设计方法已经走到了尽头，人们正在努力重构计算机系统。”</p>
<div class="com-insert-images"><figure style="margin:0;">&#13;
    <img alt="" data-ratio="0.666667" data-format="jpeg" class="lazyload" src="http://img.qdaily.com/uploads/20170918101247Wunef40mObwql3Vt.jpg-w600"/>&#13;
<figcaption class="">微软公司的黄学东（左）和道格‧伯格是为公司努力开发专用芯片的众多员工中的一员。图片版权：Ian C. Bates/《纽约时报》</figcaption></figure></div>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s3 {font: 10.5px Times; font-kerning: none} span.s4 {font-kerning: none; background-color: #ffff00} ]]></style>  </p>
<p>现有计算机设计方法的效果一直很不错。大约半个世纪以来，计算机制造商总是围绕着一个处理所有工作的芯片（CPU）打造计算机系统，而 CPU 都是由英特尔等半导体芯片制造商生产的。装在人们笔记本电脑和智能手机里的就是这种芯片。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>现在，计算机工程师们正在打造更加复杂的系统。他们不再会把所有任务都交给英特尔生产的、性能强劲的 CPU，新的计算机把工作分割成了小块，再把它们分配给更多更简单、更省电的专用芯片。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s2 {font-kerning: none} span.s3 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>Google 庞大的数据中心内部发生的改变，预示了信息产业其他公司接下来将要面对的现实。大多数 Google 服务器里依然会有中央处理器，但同时也有数不清的定制芯片和它们协同工作，负责运行驱动语音识别和其他人工智能服务的计算机算法。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s2 {font-kerning: none} span.s3 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>Google 这么做完全是出于必要。多年来，它一直拥有世界上最大的计算机网络，由数据中心和网线组成的庞大帝国分布在从加州到芬兰、再到新加坡的各个地方。但在一位 Google 的研究人员看来，这个网络还太小了。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s2 {font-kerning: none} span.s3 {font: 12.5px Georgia; font-kerning: none; color: #262626; -webkit-text-stroke: 0px #262626} span.s4 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>2011 年，Google 知名工程师杰夫·迪恩（Jeff Dean）带领一支队伍，开始深入研究神经网络的想法——从本质上讲，他们想让计算机算法可以自主学习完成任务。神经网络可以用来做很多事，比如识别对着智能手机说的话，或者辨认照片中的面孔。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>几个月的时间里，迪恩和他的团队就打造了一个新的服务，它对语言的识别能力比 Google 现有的服务精确许多。但之后迪恩意识到，全世界有十几亿台手机用的都是 Google 的安卓系统，要是每人每天使用新的语音识别服务的时间是三分钟，那么 Google 需要把现有数据中心扩大一倍才够用。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s4 {font: 12.5px Georgia; font-kerning: none; color: #262626; -webkit-text-stroke: 0px #262626} ]]></style>  </p>
<p>据当时在场的人称，迪恩对负责管理 Google 数据中心的乌尔斯·霍尔茨勒（Urs Hölzle）说：“（那样的话，）我们得再造一个 Google。”所以迪恩提出了另一个方案：Google 自制芯片，专门用来运行此类人工智能任务。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>但数据中心内部发生的变化也正在改变其他科技领域。在接下来的几年里，Google、苹果和三星等科技公司将设计出拥有专门人工智能芯片的手机。微软正在设计专门应用在一款增强现实头戴设备上的芯片。Google、丰田等正在研发自动驾驶汽车的公司也都需要类似芯片。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s4 {font: 12.5px Georgia; font-kerning: none; color: #262626; -webkit-text-stroke: 0px #262626} ]]></style>  </p>
<p>曾在美国国防部下属研究机构 Darpa 担任项目经理、如今在丰田无人驾驶汽车部门工作的吉尔·普拉特（Gill Pratt）说，研发专用芯片和新的计算机架构的趋势将带来人工智能领域的“寒武纪生命大爆发”（Cambrian explosion）。在他看来，把计算分配给众多低功耗小芯片的计算机的工作原理将更像人的大脑，它可以自行决定如何高效利用能源。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>他最近在丰田于硅谷新建的研发中心接受采访时说：“对于人的大脑来说，能量利用效率很关键。”</p>
<p><b>即将到来的变革</b></p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} ]]></style>  </p>
<p>硅基芯片有很多种，有的用于存储信息，有的可以完成玩具和电视需要的基本任务，有些芯片则可以在计算机中运行各种各样的流程。这里所说的计算机既包括了创建全球变暖模型要用到的超级计算机，也包括了个人电脑、网络服务器和智能手机。</p>
<div class="com-insert-images"><figure style="margin:0;">&#13;
    <img alt="" data-ratio="0.666504" data-format="jpeg" class="lazyload" src="http://img.qdaily.com/uploads/20170918101306VDWbrYq6yENBfGU2.jpg-w600"/>&#13;
<figcaption class="">微软办公室里的一块旧式芯片电路板。现在它正在开发的芯片可以随时进行重新编程，完成新的任务。图片版权：Ian C. Bates/《纽约时报》</figcaption></figure></div>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>多年来，个人电脑和类似设备中的 CPU 都是最昂贵的元件，过去也没有对它进行革新的需求。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 12.5px Georgia; font-kerning: none; color: #262626; -webkit-text-stroke: 0px #262626} span.s3 {font: 12.5px Georgia; text-decoration: underline ; font-kerning: none; color: #27547e; -webkit-text-stroke: 0px #27547e} span.s4 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>英特尔联合创始人戈登·摩尔（Gordon Moore）提出的摩尔定律（<a href="https://www.nytimes.com/2016/05/05/technology/moores-law-running-out-of-room-tech-looks-for-a-successor.html?_r=0" rel="nofollow">Moore’s Law</a>）经常被人们引用，它说，计算机芯片上晶体管的数量大约每两年就会翻一番，数十年来，人们一直在根据这一定律稳定地提升着计算机的性能。而根据另一个不怎么为人所知的芯片设计定律、以 IBM 资深研究人员罗伯特·登纳德（Robert Dennard）名字命名的“登纳德缩放比例定律”，随着性能的提升，芯片消耗的能量基本上会保持不变。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>然而到 2010 年时，晶体管数量翻番所花的时间比摩尔定律预计的时间长了许多。随着芯片设计师触碰到制造芯片所用材料的物理极限，登纳德缩放比例定律也不成立了。这时，如果一家公司想要更多算力，单纯升级处理器已经不行了，它需要更多的计算机、更大的空间和更多的电力。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {text-decoration: underline ; font-kerning: none; color: #0563c1; -webkit-text-stroke: 0px #0563c1} span.s3 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>行业和学界研究人员过去在努力延续摩尔定律的生命，<a href="https://www.nytimes.com/2015/09/27/technology/smaller-faster-cheaper-over-the-future-of-computer-chips.html" rel="nofollow">寻找全新的芯片制造材料和设计技术</a>。但微软的研究人员道格·伯格有另一个想法：与其像 1960 年代以来那样依靠中央处理器的稳定进步，我们何不把某些运算转到专用芯片上？</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s4 {font: 10.5px 'Times New Roman'; text-decoration: underline ; font-kerning: none; color: #0563c1; -webkit-text-stroke: 0px #0563c1} ]]></style>  </p>
<p>在 2010 年圣诞假期间，伯格和其他一些芯片研发人员留在公司工作，开始研究可以提升公司 <a href="http://www.bing.com/" rel="nofollow">Bing</a> 搜索引擎性能的新硬件。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>那时，微软刚刚开始利用机器学习算法（神经网络就是机器学习的一种）改善 Bing 的性能，通过分析人们使用搜索引擎的习惯改进搜索结果。尽管和后来重塑了互联网的神经网络相比，这些算法所需的算力要少很多，但现有芯片还是没办法有效处理。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s3 {font: 12.5px Georgia; font-kerning: none; color: #262626; -webkit-text-stroke: 0px #262626} span.s4 {font: 12.5px 'Songti SC'; font-kerning: none; color: #262626; -webkit-text-stroke: 0px #262626} span.s5 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>伯格和他的团队探索了好几种办法，但最终确定使用一种叫“现场可编程逻辑门阵列”（Field Programmable Gate Arrays，FPGA）的方案——它是一系列可以随时进行重新编程，完成新的任务的芯片。微软做的是在英特尔的 CPU 上面运行的 Windows 等各种软件，但这些软件并不能对芯片进行重新编程，因为它们的功能是固定的，只能完成特定的任务。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} ]]></style>  </p>
<p>有了现场可编程逻辑门阵列以后，微软就能改变芯片工作的方式。它可以先对芯片进行编程，让它善于执行特定的机器学习算法。然后，它可以对芯片进行再次编程，让它善于运行新的逻辑算法，把数百万数据包发送到和自己连接的整个计算机网络。芯片还是同一块芯片，但却能以不同的方式运行。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s2 {font-kerning: none} span.s3 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>2015 年，微软开始大规模部署这些芯片。现在，几乎所有新装进微软数据中心的服务器上都装了一块这种可编程芯片。当人们用 Bing 搜索时，它们会帮助选择搜索结果，它们还会帮助微软的 Azure 云计算服务在其所依赖的计算机网络内传送信息。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p><b>教电脑倾听</b></p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s2 {font-kerning: none} ]]></style>  </p>
<p>2016 年秋，另一队微软研究人员仿照 Google 杰夫·迪恩所做的工作，搭建了一套神经网络。至少一种衡量结果显示，这套神经网络可以比普通人更加准确地辨识口语。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s3 {text-decoration: underline ; font-kerning: none; color: #0563c1; -webkit-text-stroke: 0px #0563c1} ]]></style>  </p>
<p>在中国出生的语音识别专家黄学东是这个项目的负责人。研究团队发表论文阐述工作成果后，他在加州帕洛阿尔托山上和老朋友、芯片制造商英伟达（Nvidia）的首席执行官<a href="http://www.nytimes.com/2010/06/06/business/06corner.html" rel="nofollow">黄仁勋</a>（二人没有血缘关系）吃了顿晚饭。他们有理由庆祝一番，也确实开了瓶香槟干杯庆贺。</p>
<div class="com-insert-images"><figure style="margin:0;">&#13;
    <img alt="" data-ratio="0.720000" data-format="jpeg" class="lazyload" src="http://img.qdaily.com/uploads/20170918101326NYPEDI2zK618T0dZ.jpg-w600"/>&#13;
<figcaption class="">Google 知名工程师杰夫·迪恩说，公司应该开发一种芯片给人工智能用。图右为谷歌的张量处理单元（Tensor Processing Unit），简称 TPU。图片版权：Ryan Young/《纽约时报》</figcaption></figure></div>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} ]]></style>  </p>
<p>在训练他们的语音识别服务时，黄学东和微软的研究人员没有一味依赖普通的英特尔芯片，而是大量使用了英伟达提供的专用芯片。如果没有这个改变，他们不可能实现这一突破性进展。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s2 {font-kerning: none} ]]></style>  </p>
<p>“我们用了一年左右，消除了人工智能和人类之间的差距，”微软的黄学东说，“如果没有这些基础设施作为武器，我们至少得花五年时间。”</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} ]]></style>  </p>
<p>由于这些系统是靠神经网络搭建的，很大程度上可以自主学习，因此它们更新换代的速度会比传统语音识别服务更快。它们不那么需要工程师编写无数行代码，告诉它们该怎么做事。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} ]]></style>  </p>
<p>但有一个问题：用这种方式训练神经网络需要进行大量的实验和试错。为了创造能够和人类一样辨识语音的神经网络，研究人员必须不断训练它，反复调整算法、改进训练数据。在任何给定的时间里，这个过程都要运行数百个算法，这就需要庞大的计算能力。如果微软等公司使用标准芯片来做这件事，那花的时间就太久了，而且还要耗费很多电力，因为标准芯片无法承担这么庞大的计算量。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s3 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>所以，互联网巨头们现在正使用另一种名叫“图形处理单元”（graphics processing unit，简称 GPU）的芯片训练他们的神经网络。这些通常由英伟达生产的低功耗芯片原本是为渲染游戏和其他软件图像设计的，现在则与通常由英特尔生产的芯片一起，成为了计算机核心的一部分。GPU 可以比 CPU 更加高效地处理神经网络需要的数学计算。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>正因为这样，英伟达如今蒸蒸日上，向美国互联网巨头和全球各地、尤其是中国的互联网公司巨头出售了大量的 GPU。去年，公司的数据中心季度销售收入翻了三番，达到了 4.09 亿美元。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {text-decoration: underline ; font-kerning: none; color: #0563c1; -webkit-text-stroke: 0px #0563c1} span.s2 {font-kerning: none} span.s3 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p><a href="http://www.nytimes.com/2010/06/06/business/06corner.html" rel="nofollow">黄仁勋</a>近来接受采访时表示：“这就有点像互联网刚开始的时候。”换句话说，高科技领域正在迅速发生变化，而<a href="https://www.nytimes.com/2017/09/01/technology/nvidia-chipmaker.html" rel="nofollow">英伟达正处在这个变化的核心</a>。</p>
<p><b>打造专用芯片</b></p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s2 {font: 10.5px Times; font-kerning: none} span.s3 {font-kerning: none} ]]></style>  </p>
<p>GPU 是公司用来教神经网络执行某个特定任务的主要工具，但它只是神经网络开发工作的一部分。一旦神经网络学会了某项工作，它就必须把学会的能力运用到实践中，这就需要另一种计算能力了。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>比如说，训练完语音识别算法后，微软会把它做成一种在线服务，这样它才会真正开始识别人们对智能手机说出的命令。在这一阶段，GPU 就不那么高效了。因此，许多公司现在正在打造专门负责实施其他芯片已学会技能的芯片。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s2 {font-kerning: none} ]]></style>  </p>
<p>Google 已经打造了自己的专用芯片——张量处理单元，简称 TPU。英伟达也在打造类似的芯片。微软则对已被英特尔收购的阿尔特拉（Altera）的芯片进行了重新编程，以便更好地支持神经网络运行。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s3 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>其他公司也紧随其后。专为智能机生产芯片的高通公司（Qualcomm）以及许多初创公司也在研究人工智能芯片，希望在快速扩张的市场中占据一席之地。科技调研公司 IDC 预计，到 2021 年，配备非传统芯片的服务器市场将达到 68 亿美元，占到总体服务器市场的 10% 左右。</p>
<div class="com-insert-images"><figure style="margin:0;">&#13;
    <img alt="" data-ratio="0.665185" data-format="jpeg" class="lazyload" src="http://img.qdaily.com/uploads/20170918102523I74QnLdziZ0BObwA.jpg-w600"/>&#13;
<figcaption class=""><p>专用芯片在公司使用的芯片中占据的比重相对而言仍是最小的。图片版权：Ryan Young/《纽约时报》</p></figcaption></figure></div>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s3 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>伯格指出，在微软遍布世界各地的机器网络中，非传统芯片占据的比重相对而言是最小的。在提到 Google 数据中心使用的芯片时，负责 Google 网络软硬件开发的工程副总裁巴特·佐野（Bart Sano）也发表了类似的言论。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} ]]></style>  </p>
<p>掌管英特尔实验室的迈克·梅伯里（Mike Mayberry）则认为改用非传统芯片没那么重要，这或许是因为，英特尔占据了 90% 以上数据中心市场，是目前最大的传统芯片销售商。梅伯里说，如果对中央处理器进行适当的调整，它们无需额外帮助即可处理新的任务。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} ]]></style>  </p>
<p>但这股芯片新热潮正在快速传播开来，英特尔自身也越来越分裂：它某种程度上否认市场正在变化，但与此同时，它也在改变自身业务，想要跟上这股变化。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s3 {font: 10.5px Times; font-kerning: none} ]]></style>  </p>
<p>两年前，英特尔斥资 167 亿美元，收购了阿尔特拉，微软使用的可编程芯片就是这家公司生产的。据报道，去年英特尔还斥资 4.08 亿美元收购了研究神经网络执行专用芯片的 Nervana 公司。如今，在 Nervana 团队的带领下，英特尔正在研究专门用于训练、执行神经网络的芯片。</p>
<p>        <style type="text/css"><![CDATA[ p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.5px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font: 10.5px 'Times New Roman'; font-kerning: none} span.s2 {font-kerning: none} ]]></style>  </p>
<p>“他们有传统大公司的问题，”比尔·卡夫兰（Bill Coughran）提到英特尔时说，“他们需要想清楚如何进军正在成长的新领域，同时又不伤害他们原有的传统业务。”卡夫兰是硅谷投资公司红杉资本（Sequoia Capital）的合伙人，近十年来负责管理 Google 的在线服务基础设施。</p>
<p>英特尔官方就摩尔定律失效一事作出的表态，非常清楚地表露了英特尔的内部矛盾。近来接受《纽约时报》采访时，Nervana 创始人、现英特尔高管纳温·劳（Naveen Rao）表示，英特尔会再“多榨取几年”摩尔定律的效力。英特尔的官方立场是，传统芯片在未来十年仍然会发展良好。</p>
<p>英特尔的梅伯里也表示，使用额外芯片并不是什么新鲜事。他说，电脑制造商过去也会为声音处理等任务使用另外的芯片。</p>
<p>但现在，这股声势更庞大了，而且它正在以新的方式改变市场。英特尔的竞争对手不仅有英伟达、高通这样的芯片制造商，还有 Google、微软等传统科技公司。</p>
<p>Google 目前正在设计第二代 TPU 芯片。公司表示，今年晚些时候，一切使用 Google 云计算服务的企业或开发人员都将可以使用新芯片运行自己的软件。</p>
<p>这场变革目前虽然主要发生在支撑互联网的大型数据中心内部，但有可能过段时间，它就会渗透到更多行业。</p>
<p>人们希望，在这种新型移动芯片的帮助下，装置设备无需呼叫远程数据中心，即可自行处理更多更复杂的任务：手机不用接入网络就能识别语音命令；无人驾驶汽车能够以现在不可能实现的速度和精准度识别周围环境。</p>
<p>换句话说，无人驾驶汽车需要摄像头、雷达和激光，但它同样需要一个大脑。</p>
<p class=""><br/></p>
<p>翻译 熊猫译社 葛仲君 钱功毅</p>
<p nocleanhtml="true">题图来自 NYT</p>
<p>© 2017 THE NEW YORK TIMES</p>

 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>