<h1>手机相册已经能看懂你拍的是猫还是狗，怎么做到的？_智能_好奇心日报
</h1><p><img src="http://img.qdaily.com/uploads/20160918124618WGE68r1QqaUwOxkt.jpg-w600"></p><div class="article-detail-bd"><div class="author-share clearfix">   <div class="author">  <a rel="nofollow" href="javascript:void(0)" class="avatar x32 circle"><img src="http://m.qdaily.com/images/missing_face.png"/> </a>  <span class="name">Signe Brewster</span><span class="date smart-date" data-origindate="2015-06-23 16:30:53 +0800"/><script language="JavaScript" type="text/javascript"><![CDATA[var o="div",a=" style='disp",b="lay:",c="none'";document.write("<"+o+a+b+c+">")]]></script><span class="date">2015-06-23 16:30:53</span><script language="JavaScript" type="text/javascript"><![CDATA[var o="div";document.write("</"+o+">")]]></script></div>      <div class="com-share-favor" data-id="11082" data-title="《手机相册已经能看懂你拍的是猫还是狗，怎么做到的？》，来自@好奇心日报" data-pic="http://img.qdaily.com/article/article_show/20160702114512oGuFwAkUOnIg5WNP.jpg?imageMogr2/auto-orient/thumbnail/!640x380r/gravity/Center/crop/640x380/ignore-error/1" data-url="http://www.qdaily.com/articles/11082.html" data-weiboappkey="2462590045"><div class="share-favor-bd clearfix"><a rel="nofollow" data-ga-event="pc:share:weixin" href="javascript:void(0)" class="share iconfont icon-weixin"/><a rel="nofollow" data-ga-event="pc:share:weibo" href="http://service.weibo.com/share/share.php" class="share iconfont icon-weibo"/><a rel="nofollow" data-ga-event="pc:share:tengxunweixin" href="http://share.v.t.qq.com/index.php" class="share iconfont icon-tengxunweibo"/><a rel="nofollow" data-ga-event="pc:share:kongjian" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey" class="share iconfont icon-kongjian"/><a rel="nofollow" data-ga-event="pc:share:douban" href="http://www.douban.com/share/service" class="share iconfont icon-douban"/><a rel="nofollow" data-ga-event="pc:share:linkedin" href="http://www.linkedin.com/shareArticle" class="share iconfont icon-linkedin"/>  <a rel="nofollow" data-ga-event="pc:favor:aritcle" href="#" class="favor iconfont icon-heart"><span class="num  smart-count" data-origincount="62"/></a>  </div></div> </div>  <p class="excerpt">Google 的相册应用可以说是人工智能和消费结合的前沿</p>  <div class="detail">  

<p>&#13;
	<b><em><a href="https://medium.com/backchannel/how-google-s-new-photos-app-can-tell-cats-from-dogs-ffd651dfcd80" target="_blank">本文</a>由 </em><em>Medium 和 Signe Brewster 授</em><em>权《好奇心日报》发布。<b><em>Signe Brewster 是 Medium </em></b></em><span style="text-align:center;"><em>Backchannel 频</em></span><em><span style="text-align:center;">道常驻作者。</span></em></b> &#13;
</p>&#13;
<p>&#13;
	Google 相簿的产品负责人 Dave Lieb 和我都在穿越时光。他在屏幕上用两个指头往中间一捏，再在成组的照片里往下一划，在一秒钟的时间里，他就从 21 世纪回到了 1990 年代、1980 年代。&#13;
</p>&#13;
<p>&#13;
	他点了一下搜索图标，打了个“ducklings”（小鸭）进去。于是满屏幕就都是孩子玩儿的那种小鸭。在他划动着屏幕回到从前的过程中，新拍的数码照片逐渐就变成了从胶卷打印出来的照片扫描而成的、欠饱和的照片。&#13;
</p>&#13;
<p>&#13;
	“我小的时候住在德州这个水塘边上。我们家还会去拿鸭蛋……来孵小鸭，”Lieb 跟我说，“如果我回到最一开始在那儿的时候，我和我的小鸭就会在这儿。”没错，就在那儿。上周，Google 给人们的生活带来了一个强大的新大脑：一个可以搜索的相簿应用——它把 Google 在图片搜索方面的能力加入到了我们自己的私人相册里。它背后的秘密就是一种新型神经网络（neural network）——也就是可以把大量信息进行分类、并学会识别图案和高水平概念的算法。这个神经网络平衡了演算能力和效率，从而可以用来识别人、地点、物品和搜索词所对应的图像，并对其进行分类。&#13;
</p>&#13;
<p>&#13;
	“在我们身处的恶劣环境里，我们需要一个像这样的应用，”搜索软件工程师 Tom Duerig 说。2015 年，人们照了太多张照片，我们生活在一个时空跳跃的时代，再看一遍我们去年发在社交媒体上的照片的快照，就能让我们感到高兴。&#13;
</p>&#13;
<p>&#13;
	是时候弄个更智能的东西出来了。随着计算机视觉研究的缓慢发展，它已经酝酿了很多年。Google 相簿可能看起来像是一个应用，但它实际上是 Google 持续探究把人工智能应用到搜索上的最新努力。&#13;
</p>
<p><img data-format="jpg" data-ratio="0.38045" class="lazyloa lazyload" alt="" src="http://img.qdaily.com/uploads/20160918124618WGE68r1QqaUwOxkt.jpg-w600"/></p>&#13;
<p>&#13;
	每年，斯坦福大学和 Google 的计算机视觉巨头都会聚在一起，参加 ImageNet 举办的大型视觉识别挑战赛——这个比赛旨在发现从巨量图片中检测出物体的最佳方法。这个比赛是了解这一领域状况的绝佳机会，在 2014 年的比赛中，物体检测和分类的准确程度就比前一年提高了一倍。&#13;
</p>&#13;
<p>&#13;
	2014 年，由 Google 的研究人员主导的团队 GoogLeNet 在好几个分类中都位居第一，去年 9 月，他们还发表了一篇论文，描述了一个独特的新的神经网络架构，这个架构名叫“Inception”（开始），名字来源于其多层结构的设计。&#13;
</p>&#13;
<p>&#13;
	Google 相簿是第一个应用了 Inception 的大型真实世界项目。当你把一张照片上传到 Google 相簿的时候，Google 会注意到照片生成的日期和位置，并把它送到神经网络里，估计照片内容的大致信息。&#13;
</p>&#13;
<p>&#13;
	Google 相簿的神经网络是分层设置的，输入的照片从最底层进入，再从最顶层输出。打造一个更加智能的网络有一个办法，那就是增加更多的层数。Inception 有 22 层。&#13;
</p>&#13;
<p>&#13;
	如果输入的照片里是一只猫（这个典故来自 2012 年机器学习界最大的新闻，当时Google 的神经网络从 1000 万张 YouTube 视频的静止画面中学会了识别猫），那么第一层就会识别出像线条或颜色这样的简单特征。然后神经网络会把这些特征传递给下一层，这一层就可能会识别出眼睛或者耳朵来。每一层都会让特征变得更复杂，最后神经网络就会检测出足够的指标，并把它们联系起来，最终做出判断：“这是一只猫。”有了 22 层的神经网络，我们就可以分得清（比如说）“摔跤”和“拥抱”的区别——这两个抽象的概念在视觉上的差异很细微，层数少的神经网络可能就分不清楚。有时候，Google 相簿也会通过查看照片的日期和地点来“作弊”，比如这张照片可能是在国际猫节那天拍的（如果你想知道的话，国际猫节是每年的 10 月 29 日）。&#13;
</p>&#13;
<p>&#13;
	借助自己世界上最大、同时也最强大的神经网络，Google 可以进行 22 层分析，通过它们过滤出每一种颜色、形状、材质，最终从一张图片中以近似 100% 的确定性分辨出其中的物体。但它可以非常接近 100% 的确定性，只是每变得聪明一点，它都要占据许多存储空间、用掉很多计算能力——考虑到 Google 相簿可以对数十亿张图片进行分类，这也算是一个很有吸引力的挑战。&#13;
</p>&#13;
<p style="text-align:center;">&#13;
	<img width="600" height="339" title="a" alt="a" data-ratio="0.565" data-format="jpeg" class="lazyload" src="http://img.qdaily.com/uploads/20160702114511ILs18XV5lpeubFBG.jpg-w600"/><span style="text-align:justify;"><em>Google </em></span><span style="text-align:justify;"><em>的研究人员在为神经网络起名字的时候，参考了突然火遍全网络的“</em></span><i><em>we need to go deeper</em></i><span style="text-align:justify;"><em>”这句流行语（源自电影《Inception（盗梦空间）》，译注）。</em></span> &#13;
</p>&#13;
<p>&#13;
	神经网络会通过减少在逐层过滤过程中照片中所承载的信息，把这些照片转化成了  22 层中的信息的总和，而且耗费的资源也在可以承受的范围内。如果它在第一层采集到 10 个不同深度的灰色，它可能会把这些信息组合成为一份信息。通常情况下，越到后面的层，系统就会处理越来越多的数据，但有了 Inception，这个数据量从头到尾不会有太大变化。&#13;
</p>&#13;
<p>&#13;
	Google 的研究人员在论文中说，在这场打造一个最智能的神经网络的竞赛中，Inception 的目的是要确保“它们不会最终成为纯粹为了满足学术好奇心的成果，而是可以被应用于实际，甚至这个网络能以合理的成本用在大型数据集上”。所以还有什么能比一个相簿应用更实际吗？&#13;
</p>&#13;
<p>&#13;
	当全部照片都连接到神经网络上以后，它们就会一直在那里，等着你拿搜索来呼唤它们。你输入“cat”，就会显示猫；输入“Halloween”，就会显示南瓜、戏服，或者也可能会显示出碰巧在 10 月 31 号那天拍的照片。&#13;
</p>&#13;
<p>&#13;
	当人想到这种实现方式的时候，其实是完成了从机器视角向人的视角的飞跃。虽然神经网络可以通过查看 10 张猫的照片总结出其中的规律，但它自己并不会从“cat”这个词联想到猫这种动物。也就是说，把“cat”这个三字词和某一系列像素联系在一起，其实是它在经过训练以后掌握的技能。&#13;
</p>&#13;
<p>&#13;
	而这也正是 Google 搜索在最一开始的时候做的事情。在过去 14 年里，Google 一直在通过搜罗网上有文字在附近的图片，把图片和文字联系在一起。如果“cat”这个词非常频繁地和一张图片联系在一起，那么这张图里极有可能就是一只猫。&#13;
</p>&#13;
<p>&#13;
	利用这个奇大无比的、有短语和照片相对应的数据库，Google 训练相簿应用的神经网络把“cat”这个词和符合猫的强指标联系在了一起。这个神经网络因此了解到，这个被称为“cats”的东西有尖尖的耳朵，它的脸上还有明显的线条和斑点。如果有用户打了“cat”这个词，那么应用就能知道该显示哪些图片。&#13;
</p>&#13;
<p>&#13;
	这种训练是一个持续不断的过程。相簿应用的基础版是免费使用的，因此任何下载了这个应用的人，都成为了帮助改善应用功能的虚拟（无偿）团队成员。用户被邀请在应用里手动标记错误的搜索结果，但即使是被动地决定不去点搜索结果中的某一个图片，都可以告诉应用“这些结果很可能不是很准确”。&#13;
</p>&#13;
<p>&#13;
	“它并不完美，5 年前的语音识别也没那么完美，”Google 负责 Streams、相簿和分享业务的副总裁 Bradley Horowitz 说。“解决这最后百分之几的不准确率的关键，在于真正让这个应用铺到足够广，从而得到让系统不断变得越来越好的数据。”&#13;
</p>&#13;
<p>&#13;
	相簿应用的起点很高。它可以分辨出金毛和金色拉布拉多之间的差别，在更加抽象的名词面前，它的表现往往非常好：搜索 “food”（食物），它会显示出从奶酪汉堡包到鸡尾酒的所有图片。它还能提取出和节日相关的图片。&#13;
</p>&#13;
<p>&#13;
	但它的缺点也会让它犯错。我尝试着搜索了一张乐高雕塑的照片，我是在最近一次虚拟现实的大会上看到的这个雕塑。“Legos”和“virtual reality”都搜不出来结果，但更为抽象的“toy”（玩具）搜出来了。神经网络在识别一些事物方面比识别另外一些事物的表现更好。如果一个物体没有太多纹理或者浓重的线条，神经网络就会很容易被难住。除了黄色以外，实际上并没有太多东西能显示出乐高小人是用塑料块做成的。&#13;
</p>&#13;
<p>&#13;
	“人（识别物体）是从它的形状、轮廓以及光线在表面形成的阴影曲线来的，”Duerig说，“计算机不擅长做这个。”目前还不擅长。&#13;
</p>&#13;
<p>&#13;
	假以时日，Google 会基于越来越多的用户的行为来训练相簿的神经网络，扩大人们可以搜索的词语的数量和种类。它会持续调整神经网络的结构，让它在不使用更多运算能力的前提下变得更加智能。&#13;
</p>&#13;
<p>&#13;
	未来的相簿应用还会有更多的功能，不过它们会在什么时候（甚至会不会）向用户推出，目前还不清楚。今年 Google 发表的一篇论文说的就是如何应用人工智能来自动为图片生成一段说明文字。它现在可以输出简单的“主谓宾”式句子了，这已经非常棒了，但 Duerig 说，Google 的团队还在对这项技术进行完善。&#13;
</p>&#13;
<p>&#13;
	上周，我们在查找照片方面前进了一步。下一步就是把它们用起来，这种应用可能是给要分享给 Facebook 的图片自动加上说明文字，也可能是让 Gmail 知道当我们输入“childhood ducklings”（童年橡皮鸭）的时候，该自动把哪些照片自动加到附件里去。&#13;
</p>&#13;
<p>&#13;
	可能这项技术还会从照片处理延伸到 Google 知识图谱（Google Knowledge Graph）中去，它现在已经能基于我们的搜索、应用和电邮提供一部分智能功能了。Google Now 可以通过分析从 Travelocity 和 Hotels.com 发来的邮件内容，在正确的时间提示我们的旅行预订信息。那么如果它能从 Google 相簿应用里的照片里知道我们有哪个型号的汽车，并指引我们到正确的修车店或者应用里去，那会是怎样的一种情形？&#13;
</p>&#13;
<p>&#13;
	“我现在已经习惯用 Google Now 服务来管理我的旅行日程了，因为它总是会在我想知道旅行信息之前，就告诉了我想知道的事情，”Horowitz 说，“同样地，如果我认为我们可以基于这一数据向用户反馈很有价值的信息的话，我们肯定也会考虑去做到它。”&#13;
</p>&#13;
<p>&#13;
	<br/>&#13;
</p>&#13;
<p>&#13;
	翻译  is译社 葛仲君&#13;
</p>


 <div class="embed-mask"><div class="embed-bd"><span class="triangle"/><div class="play"/></div><div class="embed-control"><span class="player"/><div class="bar"><span/></div><span class="sound iconfont icon-shengyin"/></div></div><p><img data-format="jpg" data-ratio="0.456667" class="lazyload lazylood" src="http://img.qdaily.com/uploads/20160725204735MvuXsg6iz3bhj7yi.jpg-w600" alt=""/></p><p class="lazylood">喜欢这篇文章？去 App 商店搜 <a href="http://m.qdaily.com/mobile/downloads/empty/2">好奇心日报</a> ，每天看点不一样的。</p></div></div>